{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load metric_helpers\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jiwer\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for (i, c1) in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for (j, c2) in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1  # j+1 instead of j since\n",
    "            deletions = current_row[j] + 1  # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def instance_metrics(ref_labels, hyp_labels):\n",
    "    segment_records = []\n",
    "    n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors = 0, 0, 0\n",
    "    for ref, hyp in zip(ref_labels, hyp_labels):\n",
    "        n_segment_tokens += 1\n",
    "        if hyp[0] != ref[0]:\n",
    "            n_segment_seg_errors += 1\n",
    "        if hyp != ref:\n",
    "            n_segment_joint_errors += 1\n",
    "        if ref.startswith(\"E\"):\n",
    "            segment_records.append((n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors))\n",
    "            n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors = 0, 0, 0\n",
    "    \n",
    "    n_segments = len(segment_records)\n",
    "    n_tokens = 0\n",
    "    n_wrong_seg_segments = 0\n",
    "    n_wrong_seg_tokens = 0\n",
    "    n_wrong_joint_segments = 0\n",
    "    n_wrong_joint_tokens = 0\n",
    "    for (n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors) in segment_records:\n",
    "        n_tokens += n_segment_tokens\n",
    "        if n_segment_seg_errors > 0:\n",
    "            n_wrong_seg_segments += 1\n",
    "            n_wrong_seg_tokens += n_segment_tokens\n",
    "        if n_segment_joint_errors > 0:\n",
    "            n_wrong_joint_segments += 1\n",
    "            n_wrong_joint_tokens += n_segment_tokens\n",
    "\n",
    "    DSER = n_wrong_seg_segments / n_segments\n",
    "    strict_seg_err = n_wrong_seg_tokens / n_tokens\n",
    "    DER = n_wrong_joint_segments / n_segments\n",
    "    strict_joint_err = n_wrong_joint_tokens / n_tokens\n",
    "\n",
    "    ref_short = [x for x in ref_labels if x != \"I\"]\n",
    "    hyp_short = [x for x in hyp_labels if x != \"I\"]\n",
    "    lwer = jiwer.wer(ref_short, hyp_short)\n",
    "    return {\n",
    "        \"DSER\": DSER,\n",
    "        \"strict segmentation error\": strict_seg_err,\n",
    "        \"DER\": DER,\n",
    "        \"strict joint error\": strict_joint_err,\n",
    "        \"LWER\": lwer\n",
    "    }\n",
    "\n",
    "def batch_metrics(refs, hyps):\n",
    "    score_lists = {\n",
    "        \"DSER\": [],\n",
    "        \"strict segmentation error\": [],\n",
    "        \"DER\": [],\n",
    "        \"strict joint error\": [],\n",
    "        \"LWER\": []\n",
    "    }\n",
    "    for ref_labels, hyp_labels in zip(refs, hyps):\n",
    "        this_metrics = instance_metrics(ref_labels, hyp_labels)\n",
    "        for k, v in this_metrics.items():\n",
    "            score_lists[k].append(v)\n",
    "\n",
    "    flattened_refs = [label for ref in refs for label in ref]\n",
    "    flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "    macro_f1 = f1_score(flattened_refs, flattened_hyps, average=\"macro\")\n",
    "    micro_f1 = f1_score(flattened_refs, flattened_hyps, average=\"micro\")\n",
    "    flat_ref_short = [x for x in flattened_refs if x != \"I\"]\n",
    "    flat_hyp_short = [x for x in flattened_hyps if x != \"I\"]\n",
    "    lwer = jiwer.wer(flat_ref_short, flat_hyp_short)\n",
    "\n",
    "    return {\n",
    "        \"DSER\": np.mean(score_lists[\"DSER\"]),\n",
    "        \"strict segmentation error\": np.mean(score_lists[\"strict segmentation error\"]),\n",
    "        \"DER\": np.mean(score_lists[\"DER\"]),\n",
    "        \"strict joint error\": np.mean(score_lists[\"strict joint error\"]),\n",
    "        \"Macro F1\": macro_f1,\n",
    "        \"Micro F1\": micro_f1,\n",
    "        \"Macro LWER\": np.mean(score_lists[\"LWER\"]),\n",
    "        \"Micro LWER\": lwer,\n",
    "    }\n",
    "\n",
    "def instance_metrics_asr(ref_labels, hyp_labels, dist_fn=levenshtein):\n",
    "    ref_short = [x for x in ref_labels if x != \"I\"]\n",
    "    hyp_short = [x for x in hyp_labels if x != \"I\"]\n",
    "    lwer = jiwer.wer(ref_short, hyp_short)\n",
    "\n",
    "    ler = dist_fn(ref_labels, hyp_labels) / len(ref_labels)\n",
    "    \n",
    "    t_ids = [i for i, t in enumerate(ref_labels) if \"E\" in t]\n",
    "    r_ids = [i for i, r in enumerate(hyp_labels) if \"E\" in r]\n",
    "    s = 0\n",
    "    for t in t_ids: s += min([abs(r - t) for r in r_ids])\n",
    "    for r in r_ids: s += min([abs(r - t) for t in t_ids])\n",
    "        \n",
    "    ser = s / 2 / len(ref_short)\n",
    "    nser = abs(len(ref_short) - len(hyp_short)) / len(ref_short)\n",
    "    \n",
    "    new_ref = []\n",
    "    new_hyp = []\n",
    "    offset = 0\n",
    "    for i in t_ids:\n",
    "        new_ref += [ref_labels[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    offset = 0\n",
    "    for i in r_ids:\n",
    "        new_hyp += [hyp_labels[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    daer = dist_fn(new_ref, new_hyp) / len(new_ref)\n",
    "    return {\"LWER\": lwer,\n",
    "            \"LER\": ler,\n",
    "            \"SER\": ser,\n",
    "            \"NSER\": nser,\n",
    "            \"DAER\": daer}\n",
    "\n",
    "def convert_to_list(this_str, turn_float=False):\n",
    "    this_str = this_str.replace('[', '').replace(']','')\n",
    "    this_str = this_str.replace(\"'\", \"\").replace(\",\",\"\").split()\n",
    "    if turn_float:\n",
    "        this_str = [float(x) for x in this_str]\n",
    "    return this_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = \"/homes/ttmt001/transitory/dialog-act-prediction/data/joint/ref_out\"\n",
    "asr_dir = \"/homes/ttmt001/transitory/dialog-act-prediction/data/joint/asr_out\"\n",
    "\n",
    "split_name = 'dev'\n",
    "filename = split + \"_merged.tsv\"\n",
    "merged_df = pd.read_csv(filename, sep=\"\\t\")\n",
    "for column in ['joint_labels', 'da_turn_orig', 'da_turn_asr']:\n",
    "    merged_df[column] = merged_df[column].apply(convert_to_list)\n",
    "for column in ['start_times_orig', 'end_times_orig', 'start_times_asr', 'end_times_asr']:\n",
    "    merged_df[column] = merged_df[column].apply(convert_to_list, turn_float=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(model_name, split_name, merged_df):\n",
    "    suffix = split_name.upper() + '_' +  model_name + '.res'\n",
    "\n",
    "    trans_file = os.path.join(ref_dir, suffix)\n",
    "    asr_file = os.path.join(asr_dir, suffix)\n",
    "\n",
    "    trans_df = pd.read_csv(trans_file, sep=\"\\t\")\n",
    "    asr_df = pd.read_csv(asr_file, sep=\"\\t\")\n",
    "    asr_df.rename(columns={'PREDS': 'PREDS_ASR'}, inplace=True)\n",
    "    asr_df['PREDS_ASR'] = asr_df.PREDS_ASR.apply(lambda x: x.replace(\" </t>\", \"\"))\n",
    "    preds_df = trans_df.join(asr_df)\n",
    "    preds_df['labels'] = preds_df.LABELS.apply(lambda x: x.split())\n",
    "    preds_df['hyps_trans'] = preds_df.PREDS.apply(lambda x: x.split())\n",
    "    preds_df['hyps_asr'] = preds_df.PREDS_ASR.apply(lambda x: x.split())\n",
    "    preds_df.rename(columns={'TURN_ID': 'main_id'}, inplace=True)\n",
    "    preds_df.drop(columns=['LABELS', 'PREDS', 'PREDS_ASR'], inplace=True)\n",
    "    res_df = pd.merge(preds_df, merged_df, on='main_id')\n",
    "\n",
    "    results = res_df.apply(lambda row: instance_metrics(row.labels, row.hyps_trans), axis=1)\n",
    "    results_asr = res_df.apply(lambda row: instance_metrics_asr(row.labels, row.hyps_asr), axis=1)\n",
    "    results2 = res_df.apply(lambda row: instance_metrics_asr(row.labels, row.hyps_trans), axis=1)\n",
    "\n",
    "    res_df['DSER'] = [x['DSER'] for x in results.tolist()]\n",
    "    res_df['DER'] = [x['DER'] for x in results.tolist()]\n",
    "    res_df['LWER_trans'] = [x['LWER'] for x in results.tolist()]\n",
    "    res_df['LER_trans'] = [x['LER'] for x in results2.tolist()]\n",
    "    res_df['SER_trans'] = [x['SER'] for x in results2.tolist()]\n",
    "    res_df['NSER_trans'] = [x['NSER'] for x in results2.tolist()]\n",
    "    res_df['DAER_trans'] = [x['DAER'] for x in results2.tolist()]\n",
    "\n",
    "    res_df['LWER_asr'] = [x['LWER'] for x in results_asr.tolist()]\n",
    "    res_df['LER_asr'] = [x['LER'] for x in results_asr.tolist()]\n",
    "    res_df['SER_asr'] = [x['SER'] for x in results_asr.tolist()]\n",
    "    res_df['NSER_asr'] = [x['NSER'] for x in results_asr.tolist()]\n",
    "    res_df['DAER_asr'] = [x['DAER'] for x in results_asr.tolist()]\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sp10004_df = get_results_df(\"sp10004\", split_name, merged_df)\n",
    "tt10004_df = get_results_df(\"tt10004\", split_name, merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row specific (debug)\n",
    "sseq = SequenceMatcher(None, row.da_turn_asr, row.da_turn_orig)\n",
    "\n",
    "ref_side = list(zip(range(len(row.labels)),row.labels, row.start_times_orig, row.end_times_orig, row.da_turn_orig))\n",
    "ref_segments = [x for x in ref_side if \"E\" in x[1]]\n",
    "hyp_side = list(zip(range(len(row.hyps_asr)), row.hyps_asr, row.start_times_asr, row.end_times_asr, row.da_turn_asr))\n",
    "hyp_segments = [x for x in hyp_side if \"E\" in x[1]]\n",
    "\n",
    "\n",
    "ref_list = res_df.labels.tolist()\n",
    "trans_list = res_df.hyps_trans.tolist()\n",
    "asr_list = res_df.hyps_asr.tolist()\n",
    "\n",
    "batch_metrics(ref_list, trans_list)\n",
    "\n",
    "batch_metrics_asr(ref_list, asr_list)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6-torch1.7-cpu",
   "language": "python",
   "name": "py3.6-torch1.7-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
