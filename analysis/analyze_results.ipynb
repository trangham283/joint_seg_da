{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load metric_helpers\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jiwer\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['figure.dpi'] = 400\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cm_analysis(y_true, y_pred, filename, labels, ymap=None, figsize=(10,10)):\n",
    "    \"\"\"\n",
    "    Generate matrix plot of confusion matrix with pretty annotations.\n",
    "    The plot image is saved to disk.\n",
    "    args: \n",
    "      y_true:    true label of the data, with shape (nsamples,)\n",
    "      y_pred:    prediction of the data, with shape (nsamples,)\n",
    "      filename:  filename of figure file to save\n",
    "      labels:    string array, name the order of class labels in the confusion matrix.\n",
    "                 use `clf.classes_` if using scikit-learn models.\n",
    "                 with shape (nclass,).\n",
    "      ymap:      dict: any -> string, length == nclass.\n",
    "                 if not None, map the labels & ys to more understandable strings.\n",
    "                 Caution: original y_true, y_pred and labels must align.\n",
    "      figsize:   the size of the figure plotted.\n",
    "    \"\"\"\n",
    "    if ymap is not None:\n",
    "        y_pred = [ymap[yi] for yi in y_pred]\n",
    "        y_true = [ymap[yi] for yi in y_true]\n",
    "        labels = [ymap[yi] for yi in labels]\n",
    "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
    "    cm_sum = np.sum(cm, axis=1, keepdims=True)\n",
    "    cm_perc = cm / cm_sum.astype(float) * 100\n",
    "    annot = np.empty_like(cm).astype(str)\n",
    "    nrows, ncols = cm.shape\n",
    "    for i in range(nrows):\n",
    "        for j in range(ncols):\n",
    "            c = cm[i, j]\n",
    "            p = cm_perc[i, j]\n",
    "            if i == j:\n",
    "                s = cm_sum[i]\n",
    "                #annot[i, j] = '%.1f%%\\n%d/%d' % (p, c, s)\n",
    "                annot[i, j] = '%d' % (c)\n",
    "            elif c == 0:\n",
    "                annot[i, j] = ''\n",
    "            else:\n",
    "                #annot[i, j] = '%.1f%%\\n%d' % (p, c)\n",
    "                annot[i, j] = '%d' % (c)\n",
    "    cm = pd.DataFrame(cm, index=labels, columns=labels)\n",
    "    cm.index.name = 'Actual'\n",
    "    cm.columns.name = 'Predicted'\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sn.heatmap(cm, annot=annot, fmt='', ax=ax)\n",
    "    #plt.savefig(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_sseq(labels, hyps, tags=False):\n",
    "    if not tags:\n",
    "        ref_toks = labels[:]\n",
    "        pred_toks = hyps[:]\n",
    "    else:\n",
    "        ref_toks = [x[0] for x in labels]\n",
    "        pred_toks = [x[0] for x in hyps]\n",
    "        ref_tags = [x[1] for x in labels]\n",
    "        pred_tags = [x[1] for x in hyps]\n",
    "    sseq = SequenceMatcher(None, ref_toks, pred_toks)\n",
    "    for tag, i1, i2, j1, j2 in sseq.get_opcodes():\n",
    "        left = range(i1, i2)\n",
    "        right = range(j1, j2)\n",
    "        if tag == 'equal':\n",
    "            for k in range(len(left)):\n",
    "                if not tags:\n",
    "                    print(\"{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]] ))\n",
    "                else:\n",
    "                    print(\"{}\\t{}\\t{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                                  ref_tags[left[k]], pred_tags[right[k]] ))\n",
    "        elif tag == 'insert':\n",
    "            for k in range(len(right)):\n",
    "                if not tags:\n",
    "                    print(\"{}\\t{}\".format('INS', pred_toks[right[k]]))\n",
    "                else:\n",
    "                    print(\"{}\\t{}\\t{}\\t{}\".format('INS', pred_toks[right[k]], 'INS', pred_tags[right[k]] ))\n",
    "        elif tag == 'delete':\n",
    "            for k in range(len(left)):\n",
    "                if not tags:\n",
    "                    print(\"{}\\t{}\".format(ref_toks[left[k]], 'DEL'))\n",
    "                else:\n",
    "                    print(\"{}\\t{}\\t{}\\t{}\".format(ref_toks[left[k]], 'DEL', ref_tags[left[k]], 'DEL'))\n",
    "        else:\n",
    "            # replace:\n",
    "            if len(left) == len(right):\n",
    "                # same number of substitutions\n",
    "                for k in range(len(left)):\n",
    "                    if not tags:\n",
    "                        print(\"{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]]) )\n",
    "                    else:\n",
    "                        print(\"{}\\t{}\\t{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                                      ref_tags[left[k]], pred_tags[right[k]]))\n",
    "            else:\n",
    "                # make some insertions and deletions\n",
    "                if len(left) < len(right):\n",
    "                    # treat as insertions\n",
    "                    overlap = len(left)\n",
    "                    for k in range(len(right)):\n",
    "                        if k < overlap:\n",
    "                            if not tags:\n",
    "                                print(\"{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]]))\n",
    "                            else:\n",
    "                                print(\"{}\\t{}\\t{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                                              ref_tags[left[k]], pred_tags[right[k]] ))\n",
    "                        else:\n",
    "                            if not tags:\n",
    "                                print(\"{}\\t{}\".format('INS', pred_toks[right[k]]))\n",
    "                            else:\n",
    "                                print(\"{}\\t{}\\t{}\\t{}\".format('INS', pred_toks[right[k]], \n",
    "                                                              'INS', pred_tags[right[k]] ))\n",
    "                else:\n",
    "                    # treat as deletion\n",
    "                    overlap = len(right)\n",
    "                    for k in range(len(left)):\n",
    "                        if k < overlap:\n",
    "                            if not tags:\n",
    "                                print(\"{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]]))\n",
    "                            else:\n",
    "                                print(\"{}\\t{}\\t{}\\t{}\".format(ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                                              ref_tags[left[k]], pred_tags[right[k]] ))                                                              \n",
    "                           \n",
    "                        else:\n",
    "                            if not tags:\n",
    "                                print(\"{}\\t{}\".format(ref_toks[left[k]], 'DEL'))\n",
    "                            else:\n",
    "                                print(\"{}\\t{}\\t{}\\t{}\".format(ref_toks[left[k]], 'DEL', \n",
    "                                                              ref_tags[left[k]], 'DEL'))\n",
    "\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_sseq(labels, hyps):\n",
    "    columns = ['toks_label', 'toks_pred', 'tags_label', 'tags_pred']\n",
    "    list_row = []\n",
    "    ref_toks = [x[0] for x in labels]\n",
    "    pred_toks = [x[0] for x in hyps]\n",
    "    ref_tags = [x[1] for x in labels]\n",
    "    pred_tags = [x[1] for x in hyps]\n",
    "    sseq = SequenceMatcher(None, ref_toks, pred_toks)\n",
    "    for tag, i1, i2, j1, j2 in sseq.get_opcodes():\n",
    "        left = range(i1, i2)\n",
    "        right = range(j1, j2)\n",
    "        if tag == 'equal':\n",
    "            for k in range(len(left)):\n",
    "                list_row.append( (ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                  ref_tags[left[k]], pred_tags[right[k]]) )\n",
    "        elif tag == 'insert':\n",
    "            for k in range(len(right)):\n",
    "                list_row.append( ('INS', pred_toks[right[k]], 'INS', pred_tags[right[k]] ))\n",
    "        elif tag == 'delete':\n",
    "            for k in range(len(left)):\n",
    "                list_row.append((ref_toks[left[k]], 'DEL', ref_tags[left[k]], 'DEL'))\n",
    "        else:\n",
    "            # replace:\n",
    "            if len(left) == len(right):\n",
    "                # same number of substitutions\n",
    "                for k in range(len(left)):\n",
    "                    list_row.append((ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                     ref_tags[left[k]], pred_tags[right[k]]))\n",
    "            else:\n",
    "                # make some insertions and deletions\n",
    "                if len(left) < len(right):\n",
    "                    # treat as insertions\n",
    "                    overlap = len(left)\n",
    "                    for k in range(len(right)):\n",
    "                        if k < overlap:\n",
    "                            list_row.append( (ref_toks[left[k]], pred_toks[right[k]],\n",
    "                                              ref_tags[left[k]], pred_tags[right[k]] ))\n",
    "                        else:\n",
    "                            list_row.append(('INS', pred_toks[right[k]], \n",
    "                                             'INS', pred_tags[right[k]] ))\n",
    "                else:\n",
    "                    # treat as deletion\n",
    "                    overlap = len(right)\n",
    "                    for k in range(len(left)):\n",
    "                        if k < overlap:\n",
    "                            list_row.append((ref_toks[left[k]], pred_toks[right[k]], \n",
    "                                             ref_tags[left[k]], pred_tags[right[k]] ))                                                              \n",
    "                           \n",
    "                        else:\n",
    "                            list_row.append((ref_toks[left[k]], 'DEL', \n",
    "                                             ref_tags[left[k]], 'DEL'))\n",
    "\n",
    "    #list_row = ['toks_label', 'toks_pred', 'tags_label', 'tags_pred']\n",
    "    return pd.DataFrame(list_row, columns=columns)\n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes, normalize=False,\n",
    "        title='Confusion matrix', cmap=plt.cm.Blues, va=\"center\"):\n",
    "    import itertools\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Confusion matrix, normalized\")\n",
    "    else:\n",
    "        print('Confusion matrix, raw counts')\n",
    "    print(cm)\n",
    "    #fig = plt.figure(figsize=(12,8), dpi= 100, facecolor='w', edgecolor='k')\n",
    "    plt.figure()\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                horizontalalignment=\"center\", verticalalignment=va,\n",
    "                color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "    plt.xlabel('predicted')\n",
    "    plt.ylabel('label')\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for (i, c1) in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for (j, c2) in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1  # j+1 instead of j since\n",
    "            deletions = current_row[j] + 1  # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def instance_metrics(ref_labels, hyp_labels):\n",
    "    segment_records = []\n",
    "    n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors = 0, 0, 0\n",
    "    for ref, hyp in zip(ref_labels, hyp_labels):\n",
    "        n_segment_tokens += 1\n",
    "        if hyp[0] != ref[0]:\n",
    "            n_segment_seg_errors += 1\n",
    "        if hyp != ref:\n",
    "            n_segment_joint_errors += 1\n",
    "        if ref.startswith(\"E\"):\n",
    "            segment_records.append((n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors))\n",
    "            n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors = 0, 0, 0\n",
    "    \n",
    "    n_segments = len(segment_records)\n",
    "    n_tokens = 0\n",
    "    n_wrong_seg_segments = 0\n",
    "    n_wrong_seg_tokens = 0\n",
    "    n_wrong_joint_segments = 0\n",
    "    n_wrong_joint_tokens = 0\n",
    "    for (n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors) in segment_records:\n",
    "        n_tokens += n_segment_tokens\n",
    "        if n_segment_seg_errors > 0:\n",
    "            n_wrong_seg_segments += 1\n",
    "            n_wrong_seg_tokens += n_segment_tokens\n",
    "        if n_segment_joint_errors > 0:\n",
    "            n_wrong_joint_segments += 1\n",
    "            n_wrong_joint_tokens += n_segment_tokens\n",
    "\n",
    "    DSER = n_wrong_seg_segments / n_segments\n",
    "    strict_seg_err = n_wrong_seg_tokens / n_tokens\n",
    "    DER = n_wrong_joint_segments / n_segments\n",
    "    strict_joint_err = n_wrong_joint_tokens / n_tokens\n",
    "\n",
    "    ref_short = [x for x in ref_labels if x != \"I\"]\n",
    "    hyp_short = [x for x in hyp_labels if x != \"I\"]\n",
    "    lwer = jiwer.wer(ref_short, hyp_short)\n",
    "    return {\n",
    "        \"DSER\": DSER,\n",
    "        \"strict segmentation error\": strict_seg_err,\n",
    "        \"DER\": DER,\n",
    "        \"strict joint error\": strict_joint_err,\n",
    "        \"LWER\": lwer\n",
    "    }\n",
    "\n",
    "def batch_metrics(refs, hyps):\n",
    "    score_lists = {\n",
    "        \"DSER\": [],\n",
    "        \"strict segmentation error\": [],\n",
    "        \"DER\": [],\n",
    "        \"strict joint error\": [],\n",
    "        \"LWER\": []\n",
    "    }\n",
    "    for ref_labels, hyp_labels in zip(refs, hyps):\n",
    "        this_metrics = instance_metrics(ref_labels, hyp_labels)\n",
    "        for k, v in this_metrics.items():\n",
    "            score_lists[k].append(v)\n",
    "\n",
    "    flattened_refs = [label for ref in refs for label in ref]\n",
    "    flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "    macro_f1 = f1_score(flattened_refs, flattened_hyps, average=\"macro\")\n",
    "    micro_f1 = f1_score(flattened_refs, flattened_hyps, average=\"micro\")\n",
    "    flat_ref_short = [x for x in flattened_refs if x != \"I\"]\n",
    "    flat_hyp_short = [x for x in flattened_hyps if x != \"I\"]\n",
    "    lwer = jiwer.wer(flat_ref_short, flat_hyp_short)\n",
    "\n",
    "    return {\n",
    "        \"DSER\": np.mean(score_lists[\"DSER\"]),\n",
    "        \"strict segmentation error\": np.mean(score_lists[\"strict segmentation error\"]),\n",
    "        \"DER\": np.mean(score_lists[\"DER\"]),\n",
    "        \"strict joint error\": np.mean(score_lists[\"strict joint error\"]),\n",
    "        \"Macro F1\": macro_f1,\n",
    "        \"Micro F1\": micro_f1,\n",
    "        \"Macro LWER\": np.mean(score_lists[\"LWER\"]),\n",
    "        \"Micro LWER\": lwer,\n",
    "    }\n",
    "\n",
    "def instance_metrics_asr(ref_labels, hyp_labels):\n",
    "    ref_short = [x for x in ref_labels if x != \"I\"]\n",
    "    hyp_short = [x for x in hyp_labels if x != \"I\"]\n",
    "    lwer = jiwer.wer(ref_short, hyp_short)\n",
    "\n",
    "    ler = jiwer.wer(ref_labels, hyp_labels)\n",
    "    \n",
    "    t_ids = [i for i, t in enumerate(ref_labels) if \"E\" in t]\n",
    "    r_ids = [i for i, r in enumerate(hyp_labels) if \"E\" in r]\n",
    "    s = 0\n",
    "    for t in t_ids: \n",
    "        if r_ids:\n",
    "            dist_t = min([abs(r - t) for r in r_ids]) \n",
    "        else:\n",
    "            dist_t = len(t_ids)\n",
    "        s += dist_t\n",
    "\n",
    "    if r_ids:\n",
    "        for r in r_ids: \n",
    "            s += min([abs(r - t) for t in t_ids])\n",
    "    else:\n",
    "        s += len(t_ids)\n",
    "        \n",
    "    ser = s / 2 / len(ref_labels)\n",
    "    nser = abs(len(ref_short) - len(hyp_short)) / len(ref_short)\n",
    "    \n",
    "    new_ref = []\n",
    "    new_hyp = []\n",
    "    offset = 0\n",
    "    for i in t_ids:\n",
    "        new_ref += [ref_labels[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    offset = 0\n",
    "    for i in r_ids:\n",
    "        new_hyp += [hyp_labels[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    daer = jiwer.wer(new_ref, new_hyp)\n",
    "    return {\"LWER\": lwer,\n",
    "            \"LER\": ler,\n",
    "            \"SER\": ser,\n",
    "            \"NSER\": nser,\n",
    "            \"DAER\": daer}\n",
    "\n",
    "\n",
    "def compute_aser(refs, hyps):\n",
    "    df = align_sseq(refs, hyps)\n",
    "    #columns = ['toks_label', 'toks_pred', 'tags_label', 'tags_pred']\n",
    "    ref_labels = df.tags_label.tolist()\n",
    "    hyp_labels = df.tags_pred.tolist()\n",
    "    t_ids = [i for i, t in enumerate(ref_labels) if \"E_\" in t]\n",
    "    r_ids = [i for i, r in enumerate(hyp_labels) if \"E_\" in r]\n",
    "    s = 0\n",
    "    for t in t_ids: \n",
    "        if r_ids:\n",
    "            dist_t = min([abs(r - t) for r in r_ids]) \n",
    "        else:\n",
    "            dist_t = len(t_ids)\n",
    "        s += dist_t\n",
    "\n",
    "    if r_ids:\n",
    "        for r in r_ids: \n",
    "            s += min([abs(r - t) for t in t_ids])\n",
    "    else:\n",
    "        s += len(t_ids)\n",
    "        \n",
    "    ser = s / 2 / len(refs)\n",
    "    return ser\n",
    "    \n",
    "    \n",
    "def batch_metrics_asr(refs, hyps):\n",
    "    score_lists = {\n",
    "        \"LWER\": [],\n",
    "        \"LER\": [],\n",
    "        \"SER\": [],\n",
    "        \"NSER\": [],\n",
    "        \"DAER\": []\n",
    "    }\n",
    "    for ref_labels, hyp_labels in zip(refs, hyps):\n",
    "        this_metrics = instance_metrics_asr(ref_labels, hyp_labels)\n",
    "        for k, v in this_metrics.items():\n",
    "            score_lists[k].append(v)\n",
    "\n",
    "    flattened_refs = [label for ref in refs for label in ref]\n",
    "    flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "    flat_ref_short = [x for x in flattened_refs if x != \"I\"]\n",
    "    flat_hyp_short = [x for x in flattened_hyps if x != \"I\"]\n",
    "    lwer = jiwer.wer(flat_ref_short, flat_hyp_short)\n",
    "    ler = jiwer.wer(flattened_refs, flattened_hyps)\n",
    "    \n",
    "    t_ids = [i for i, t in enumerate(flattened_refs) if \"E\" in t]\n",
    "    r_ids = [i for i, r in enumerate(flattened_hyps) if \"E\" in r]\n",
    "    s = 0\n",
    "    for t in t_ids: s += min([abs(r - t) for r in r_ids])\n",
    "    for r in r_ids: s += min([abs(r - t) for t in t_ids])\n",
    "    ser = s / 2 / len(flattened_refs)\n",
    "    \n",
    "    nser = abs(len(t_ids) - len(r_ids)) / len(t_ids)\n",
    "    \n",
    "    new_ref = []\n",
    "    new_hyp = []\n",
    "    offset = 0\n",
    "    for i in t_ids:\n",
    "        new_ref += [flattened_refs[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    offset = 0\n",
    "    for i in r_ids:\n",
    "        new_hyp += [flattened_hyps[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    daer = jiwer.wer(new_ref, new_hyp)\n",
    "\n",
    "    return {\n",
    "        \"Macro LWER\": np.mean(score_lists[\"LWER\"]),\n",
    "        \"Micro LWER\": lwer,\n",
    "        \"Macro LER\": np.mean(score_lists[\"LER\"]),\n",
    "        \"Micro LER\": ler,\n",
    "        \"Macro SER\": np.mean(score_lists[\"SER\"]),\n",
    "        \"Micro SER\": ser,\n",
    "        \"Macro NSER\": np.mean(score_lists[\"NSER\"]),\n",
    "        \"Micro NSER\": nser,\n",
    "        \"Macro DAER\": np.mean(score_lists[\"DAER\"]),\n",
    "        \"Micro DAER\": daer,\n",
    "    }\n",
    "\n",
    "def calc_time_ser(labels, hyps, start_times_orig, end_times_orig, start_times_asr, end_times_asr):\n",
    "    t_ids = [i for i, t in enumerate(labels) if \"E\" in t]\n",
    "    r_ids = [i for i, r in enumerate(hyps) if \"E\" in r]\n",
    "\n",
    "    stime_label = [start_times_orig[i] for i in t_ids]\n",
    "    etime_label = [end_times_orig[i] for i in t_ids]\n",
    "\n",
    "    stime_asr = [start_times_asr[i] for i in r_ids]\n",
    "    etime_asr = [end_times_asr[i] for i in r_ids]\n",
    "    \n",
    "    s = 0\n",
    "    for t in stime_label: s += min([abs(r - t) for r in stime_asr]) \n",
    "    for r in stime_asr: s += min([abs(r - t) for t in stime_label])\n",
    "    for t in etime_label: s += min([abs(r - t) for r in etime_asr]) \n",
    "    for r in etime_asr: s += min([abs(r - t) for t in etime_label])\n",
    "        \n",
    "    return s / 4 / len(t_ids)     \n",
    "\n",
    "\n",
    "def convert_to_list(this_str, turn_float=False):\n",
    "    this_str = this_str.replace('[', '').replace(']','')\n",
    "    this_str = this_str.replace(\"'\", \"\").replace(\",\",\"\").split()\n",
    "    if turn_float:\n",
    "        this_str = [float(x) for x in this_str]\n",
    "    return this_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(model_name, split_name, merged_df):\n",
    "    suffix = split_name.upper() + '_' +  model_name + '.res'\n",
    "\n",
    "    trans_file = os.path.join(ref_dir, suffix)\n",
    "    asr_file = os.path.join(asr_dir, suffix)\n",
    "\n",
    "    trans_df = pd.read_csv(trans_file, sep=\"\\t\")\n",
    "    asr_df = pd.read_csv(asr_file, sep=\"\\t\")\n",
    "    asr_df.rename(columns={'PREDS': 'PREDS_ASR'}, inplace=True)\n",
    "    asr_df['PREDS_ASR'] = asr_df.PREDS_ASR.apply(lambda x: x.replace(\" </t>\", \"\"))\n",
    "    preds_df = trans_df.join(asr_df)\n",
    "    preds_df['labels'] = preds_df.LABELS.apply(lambda x: x.split())\n",
    "    preds_df['hyps_trans'] = preds_df.PREDS.apply(lambda x: x.split())\n",
    "    preds_df['hyps_asr'] = preds_df.PREDS_ASR.apply(lambda x: x.split())\n",
    "    preds_df.rename(columns={'TURN_ID': 'main_id'}, inplace=True)\n",
    "    preds_df.drop(columns=['LABELS', 'PREDS', 'PREDS_ASR'], inplace=True)\n",
    "    res_df = pd.merge(preds_df, merged_df, on='main_id')\n",
    "\n",
    "    results = res_df.apply(lambda row: instance_metrics(row.labels, row.hyps_trans), axis=1)\n",
    "    results_asr = res_df.apply(lambda row: instance_metrics_asr(row.labels, row.hyps_asr), axis=1)\n",
    "    results2 = res_df.apply(lambda row: instance_metrics_asr(row.labels, row.hyps_trans), axis=1)\n",
    "\n",
    "    res_df['DSER'] = [x['DSER'] for x in results.tolist()]\n",
    "    res_df['DER'] = [x['DER'] for x in results.tolist()]\n",
    "    res_df['LWER_trans'] = [x['LWER'] for x in results.tolist()]\n",
    "    res_df['LER_trans'] = [x['LER'] for x in results2.tolist()]\n",
    "    res_df['SER_trans'] = [x['SER'] for x in results2.tolist()]\n",
    "    res_df['NSER_trans'] = [x['NSER'] for x in results2.tolist()]\n",
    "    res_df['DAER_trans'] = [x['DAER'] for x in results2.tolist()]\n",
    "\n",
    "    res_df['LWER_asr'] = [x['LWER'] for x in results_asr.tolist()]\n",
    "    res_df['LER_asr'] = [x['LER'] for x in results_asr.tolist()]\n",
    "    res_df['SER_asr'] = [x['SER'] for x in results_asr.tolist()]\n",
    "    res_df['NSER_asr'] = [x['NSER'] for x in results_asr.tolist()]\n",
    "    res_df['DAER_asr'] = [x['DAER'] for x in results_asr.tolist()]\n",
    "    \n",
    "    res_df['ASER_asr'] = res_df.apply(lambda row: \n",
    "                                  compute_aser( list(zip(row.da_turn_orig, row.labels)), \n",
    "                                               list(zip(row.da_turn_asr, row.hyps_asr)) ),\n",
    "                                  axis=1)\n",
    "    res_df['ASER_trans'] = res_df.apply(lambda row: \n",
    "                                  compute_aser( list(zip(row.da_turn_orig, row.labels)), \n",
    "                                               list(zip(row.da_turn_orig, row.hyps_trans)) ),\n",
    "                                  axis=1)\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Small examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [\"E_b\", \"E_sv\", \"I\", \"I\", \"E_sd\"]\n",
    "preds = [\"E_aa\", \"I\", \"I\", \"E_sv\", \"E_sd\"]\n",
    "asr = [\"E_ny\", \"I\", \"I\", \"E_sv\", \"E_sd\", \"E_ny\"]\n",
    "\n",
    "toks2 = [\"right\", \"yes\", \"he\", \"loves\", \"cats\"]\n",
    "astoks2 = [\"yes\", \"yes\", \"he\", \"loves\", \"cats\", \"yes\"]\n",
    "#instance_metrics(labels, preds)\n",
    "#batch_metrics([labels], [preds])\n",
    "#instance_metrics_asr(labels, asr)\n",
    "compute_aser(list(zip(toks2, labels)), list(zip(astoks2, asr)))\n",
    "\n",
    "#f1_score(labels, preds, average=\"micro\")\n",
    "l = ['b', 'sv', 'sd', 'sd', 'sd']\n",
    "h = ['ny', 'sv', 'sv', 'sv', 'sd', 'ny']\n",
    "jiwer.wer(l, h)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ref_dir = \"/homes/ttmt001/transitory/dialog-act-prediction/data/joint/ref_out\"\n",
    "asr_dir = \"/homes/ttmt001/transitory/dialog-act-prediction/data/joint/asr_out\"\n",
    "\n",
    "dialog_acts = ['sd', 'b', 'sv', '%', 'aa', 'ba', 'qy', 'ny', 'fc',\n",
    "                'qw', 'nn', 'bk', 'fo_o_fw_\"_by_bc', 'h', 'qy^d', 'bh', '^q',\n",
    "                'bf', 'na', 'ad', '^2', 'b^m', 'qo', 'qh', '^h', 'ar', 'ng',\n",
    "                'br', 'no', 'fp', 'qrr', 'arp_nd', 't3', 'oo_co_cc', 't1', 'bd',\n",
    "                'aap_am', '^g', 'qw^d', 'fa', 'ft']\n",
    "joint_labels = [\"I\"] + [\"E_\"+da for da in dialog_acts]\n",
    "label_map = dict(zip(range(len(joint_labels)), joint_labels))\n",
    "#label_map\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_name = 'dev'\n",
    "filename = split_name + \"_merged.tsv\"\n",
    "merged_df = pd.read_csv(filename, sep=\"\\t\")\n",
    "for column in ['joint_labels', 'da_turn_orig', 'da_turn_asr']:\n",
    "    merged_df[column] = merged_df[column].apply(convert_to_list)\n",
    "for column in ['start_times_orig', 'end_times_orig', 'start_times_asr', 'end_times_asr']:\n",
    "    merged_df[column] = merged_df[column].apply(convert_to_list, turn_float=True)\n",
    "\n",
    "sp10004_df = get_results_df(\"sp10004\", split_name, merged_df)\n",
    "sp30004_df = get_results_df(\"sp30004\", split_name, merged_df)\n",
    "\n",
    "tt1000_df = get_results_df(\"tt1000\", split_name, merged_df)\n",
    "tt3000_df = get_results_df(\"tt3000\", split_name, merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Diagnostics\n",
    "\n",
    "# WER \n",
    "tokens = sp10004_df.da_turn_orig.tolist()\n",
    "tokens = [label for ref in tokens for label in ref]\n",
    "asr = sp10004_df.da_turn_asr.tolist()\n",
    "asr = [label for ref in asr for label in ref]\n",
    "jiwer.wer(tokens,asr)\n",
    "\n",
    "refs = sp10004_df.labels.tolist()\n",
    "hyps = sp10004_df.hyps_asr.tolist()\n",
    "trans = sp10004_df.hyps_trans.tolist()\n",
    "flattened_refs = [label for ref in refs for label in ref]\n",
    "flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "flattened_trans = [label for hyp in trans for label in hyp]\n",
    "\n",
    "refs = sp10004_df.da_turn_orig.tolist()\n",
    "hyps = sp10004_df.da_turn_asr.tolist()\n",
    "flattened_refs_toks = [label for ref in refs for label in ref]\n",
    "flattened_hyps_toks = [label for hyp in hyps for label in hyp]\n",
    "\n",
    "aa = list(zip(flattened_refs_toks, flattened_refs))\n",
    "bb = list(zip(flattened_hyps_toks, flattened_hyps))\n",
    "cc = list(zip(flattened_refs_toks, flattened_trans))\n",
    "\n",
    "print(\"Prosody mode, trans:\")\n",
    "print(\"Macro ASER:\", sp10004_df.ASER_trans.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, cc))\n",
    "\n",
    "print(\"Prosody mode, asr:\")\n",
    "print(\"Macro ASER:\", sp10004_df.ASER_asr.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, bb))\n",
    "\n",
    "#print(\"Macro SER:\", sp10004_df.SER_asr.mean())\n",
    "\n",
    "refs = tt1000_df.labels.tolist()\n",
    "hyps = tt1000_df.hyps_asr.tolist()\n",
    "trans = tt1000_df.hyps_trans.tolist()\n",
    "flattened_refs = [label for ref in refs for label in ref]\n",
    "flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "flattened_trans = [label for hyp in trans for label in hyp]\n",
    "\n",
    "refs = tt1000_df.da_turn_orig.tolist()\n",
    "hyps = tt1000_df.da_turn_asr.tolist()\n",
    "flattened_refs_toks = [label for ref in refs for label in ref]\n",
    "flattened_hyps_toks = [label for hyp in hyps for label in hyp]\n",
    "\n",
    "aa = list(zip(flattened_refs_toks, flattened_refs))\n",
    "bb = list(zip(flattened_hyps_toks, flattened_hyps))\n",
    "cc = list(zip(flattened_refs_toks, flattened_trans))\n",
    "\n",
    "print(\"Text model, trans:\")\n",
    "print(\"Macro ASER:\", tt1000_df.ASER_trans.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, cc))\n",
    "\n",
    "print(\"Text mode, asr:\")\n",
    "print(\"Macro ASER:\", tt1000_df.ASER_asr.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sp10004_df.iloc[1].da_turn_asr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics(sp10004_df.labels.tolist(), sp10004_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics(tt1000_df.labels.tolist(), tt1000_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(sp10004_df.labels.tolist(), sp10004_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(tt1000_df.labels.tolist(), tt1000_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(sp10004_df.labels.tolist(), sp10004_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(tt1000_df.labels.tolist(), tt1000_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sp10004_df.head(3)\n",
    "#tt1000_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp5001_df = get_results_df(\"sp5001\", split_name, merged_df)\n",
    "tt5001_df = get_results_df(\"tt5001\", split_name, merged_df)\n",
    "\n",
    "batch_metrics_asr(tt5001_df.labels.tolist(), tt5001_df.hyps_trans.tolist())\n",
    "\n",
    "batch_metrics_asr(sp5001_df.labels.tolist(), sp5001_df.hyps_trans.tolist())\n",
    "\n",
    "batch_metrics_asr(tt5001_df.labels.tolist(), tt5001_df.hyps_asr.tolist())\n",
    "\n",
    "batch_metrics_asr(sp5001_df.labels.tolist(), sp5001_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On test set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"test_merged.tsv\"\n",
    "mt_df = pd.read_csv(filename, sep=\"\\t\")\n",
    "for column in ['joint_labels', 'da_turn_orig', 'da_turn_asr']:\n",
    "    mt_df[column] = mt_df[column].apply(convert_to_list)\n",
    "for column in ['start_times_orig', 'end_times_orig', 'start_times_asr', 'end_times_asr']:\n",
    "    mt_df[column] = mt_df[column].apply(convert_to_list, turn_float=True)\n",
    "\n",
    "test_sp10004_df = get_results_df(\"sp10004\", \"test\", mt_df)\n",
    "test_tt1000_df = get_results_df(\"tt1000\", \"test\", mt_df)\n",
    "#test_sp30004_df = get_results_df(\"sp30004\", \"test\", mt_df)\n",
    "#test_tt3000_df = get_results_df(\"tt3000\", \"test\", mt_df)\n",
    "\n",
    "tokens = test_sp10004_df.da_turn_orig.tolist()\n",
    "tokens = [label for ref in tokens for label in ref]\n",
    "asr = test_sp10004_df.da_turn_asr.tolist()\n",
    "asr = [label for ref in asr for label in ref]\n",
    "\n",
    "jiwer.wer(tokens,asr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(\"Macro SER:\", sp10004_df.SER_asr.mean())\n",
    "\n",
    "refs = test_sp10004_df.labels.tolist()\n",
    "hyps = test_sp10004_df.hyps_asr.tolist()\n",
    "trans = test_sp10004_df.hyps_trans.tolist()\n",
    "flattened_refs = [label for ref in refs for label in ref]\n",
    "flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "flattened_trans = [label for hyp in trans for label in hyp]\n",
    "\n",
    "refs = test_sp10004_df.da_turn_orig.tolist()\n",
    "hyps = test_sp10004_df.da_turn_asr.tolist()\n",
    "flattened_refs_toks = [label for ref in refs for label in ref]\n",
    "flattened_hyps_toks = [label for hyp in hyps for label in hyp]\n",
    "\n",
    "aa = list(zip(flattened_refs_toks, flattened_refs))\n",
    "bb = list(zip(flattened_hyps_toks, flattened_hyps))\n",
    "cc = list(zip(flattened_refs_toks, flattened_trans))\n",
    "\n",
    "print(\"Prosody mode, trans:\")\n",
    "print(\"Macro ASER:\", test_sp10004_df.ASER_trans.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, cc))\n",
    "\n",
    "print(\"Prosody mode, asr:\")\n",
    "print(\"Macro ASER:\", test_sp10004_df.ASER_asr.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, bb))\n",
    "\n",
    "#print(\"Macro SER:\", sp10004_df.SER_asr.mean())\n",
    "\n",
    "refs = test_tt1000_df.labels.tolist()\n",
    "hyps = test_tt1000_df.hyps_asr.tolist()\n",
    "trans = test_tt1000_df.hyps_trans.tolist()\n",
    "flattened_refs = [label for ref in refs for label in ref]\n",
    "flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "flattened_trans = [label for hyp in trans for label in hyp]\n",
    "\n",
    "refs = test_tt1000_df.da_turn_orig.tolist()\n",
    "hyps = test_tt1000_df.da_turn_asr.tolist()\n",
    "flattened_refs_toks = [label for ref in refs for label in ref]\n",
    "flattened_hyps_toks = [label for hyp in hyps for label in hyp]\n",
    "\n",
    "aa = list(zip(flattened_refs_toks, flattened_refs))\n",
    "bb = list(zip(flattened_hyps_toks, flattened_hyps))\n",
    "cc = list(zip(flattened_refs_toks, flattened_trans))\n",
    "\n",
    "print(\"Text model, trans:\")\n",
    "print(\"Macro ASER:\", test_tt1000_df.ASER_trans.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, cc))\n",
    "\n",
    "print(\"Text model, asr:\")\n",
    "print(\"Macro ASER:\", test_tt1000_df.ASER_asr.mean())\n",
    "print(\"Micro ASER:\", compute_aser(aa, bb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(test_tt1000_df.labels.tolist(), test_tt1000_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(test_sp10004_df.labels.tolist(), test_sp10004_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(test_tt1000_df.labels.tolist(), test_tt1000_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics_asr(test_sp10004_df.labels.tolist(), test_sp10004_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics(test_tt1000_df.labels.tolist(), test_tt1000_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_metrics(test_sp10004_df.labels.tolist(), test_sp10004_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Questions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Where does speech model help, given perfect transcript?\n",
    "2. Which tags get confused most in the transcript vs. in speech model?\n",
    "3. Where does speech model help, on ASR?\n",
    "4. Which tags get confused most in ASR using only ASR transcript vs. ASR transcript + speech?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "rename_cols = [\"hyps_trans\", \"hyps_asr\", \"DSER\", \"DER\", \"LWER_trans\", \"LER_trans\",\n",
    "              \"SER_trans\", \"NSER_trans\", \"DAER_trans\", \"ASER_trans\", \"ASER_asr\",\n",
    "              \"LWER_asr\", \"LER_asr\", \"SER_asr\", \"NSER_asr\", \"DAER_asr\"]\n",
    "dup_cols = [\"labels\", \"joint_labels\", \"da_turn_orig\", \"da_turn_asr\",\n",
    "           \"start_times_orig\", \"start_times_asr\", \"end_times_orig\", \"end_times_asr\"]\n",
    "\n",
    "new_sp = [x+'_sp' for x in rename_cols]\n",
    "new_tt = [x+'_tt' for x in rename_cols]\n",
    "temp_sp = sp10004_df.rename(columns = dict(zip(rename_cols, new_sp)))\n",
    "temp_tt = tt1000_df.rename(columns = dict(zip(rename_cols, new_tt)))\n",
    "temp_tt.drop(columns = dup_cols, inplace=True)\n",
    "\n",
    "new_df = pd.merge(temp_sp, temp_tt, on=\"main_id\")\n",
    "new_df['num_seg_label'] = new_df.labels.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new_df['num_seg_trans_sp'] = new_df.hyps_trans_sp.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new_df['num_seg_asr_sp'] = new_df.hyps_asr_sp.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new_df['num_seg_trans_tt'] = new_df.hyps_trans_tt.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new_df['num_seg_asr_tt'] = new_df.hyps_asr_tt.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "\n",
    "new_df['diff_seg_trans_sp'] = new_df['num_seg_trans_sp'] - new_df['num_seg_label'] \n",
    "new_df['diff_seg_trans_tt'] = new_df['num_seg_trans_tt'] - new_df['num_seg_label'] \n",
    "new_df['diff_seg_asr_sp'] = new_df['num_seg_asr_sp'] - new_df['num_seg_label'] \n",
    "new_df['diff_seg_asr_tt'] = new_df['num_seg_asr_tt'] - new_df['num_seg_label'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## History length = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_sp = sp30004_df.rename(columns = dict(zip(rename_cols, new_sp)))\n",
    "temp_tt = tt3000_df.rename(columns = dict(zip(rename_cols, new_tt)))\n",
    "temp_tt.drop(columns = dup_cols, inplace=True)\n",
    "\n",
    "new3_df = pd.merge(temp_sp, temp_tt, on=\"main_id\")\n",
    "new3_df['num_seg_label'] = new3_df.labels.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new3_df['num_seg_trans_sp'] = new3_df.hyps_trans_sp.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new3_df['num_seg_asr_sp'] = new3_df.hyps_asr_sp.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new3_df['num_seg_trans_tt'] = new3_df.hyps_trans_tt.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "new3_df['num_seg_asr_tt'] = new3_df.hyps_asr_tt.apply(lambda x: len([y for y in x if \"E\" in y]))\n",
    "\n",
    "new3_df['diff_seg_trans_sp'] = new3_df['num_seg_trans_sp'] - new3_df['num_seg_label'] \n",
    "new3_df['diff_seg_trans_tt'] = new3_df['num_seg_trans_tt'] - new3_df['num_seg_label'] \n",
    "new3_df['diff_seg_asr_sp'] = new3_df['num_seg_asr_sp'] - new3_df['num_seg_label'] \n",
    "new3_df['diff_seg_asr_tt'] = new3_df['num_seg_asr_tt'] - new3_df['num_seg_label'] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## More analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "measures1 = [\"DER\", \"DSER\"]\n",
    "measures2 = [\"SER\", \"NSER\", \"LER\", \"LWER\", \"DAER\", \"ASER\"]\n",
    "measure_cols_trans = []\n",
    "measure_cols_asr = []\n",
    "\n",
    "for m in measures1:\n",
    "    new_df['sptt_diff_' + m] = new_df[m + \"_tt\"] - new_df[m + \"_sp\"]\n",
    "    measure_cols_trans += ['sptt_diff_' + m]\n",
    "\n",
    "suffix = 'trans'\n",
    "for m in measures2:\n",
    "    new_df['sptt_diff_' + suffix + '_' + m] = new_df[m+\"_\"+suffix +\"_tt\"] - new_df[m+\"_\"+suffix+\"_sp\"]\n",
    "    measure_cols_trans += ['sptt_diff_' + suffix + '_' + m]\n",
    "\n",
    "suffix = 'asr'\n",
    "for m in measures2:\n",
    "    new_df['sptt_diff_' + suffix + '_' + m] = new_df[m+\"_\"+suffix +\"_tt\"] - new_df[m+\"_\"+suffix+\"_sp\"]\n",
    "    measure_cols_asr += ['sptt_diff_' + suffix + '_' + m]\n",
    "    \n",
    "measure_cols = measure_cols_trans + measure_cols_asr\n",
    "\n",
    "metric_cols = [\"DER_tt\", \"DSER_tt\", \"DER_sp\", \"DSER_sp\",\n",
    "              \"SER_trans_tt\", \"NSER_trans_tt\", \"LER_trans_tt\", \"LWER_trans_tt\", \"DAER_trans_tt\",\n",
    "              \"SER_trans_sp\", \"NSER_trans_sp\", \"LER_trans_sp\", \"LWER_trans_sp\", \"DAER_trans_sp\",\n",
    "              \"SER_asr_tt\", \"NSER_asr_tt\", \"LER_asr_tt\", \"LWER_asr_tt\", \"DAER_asr_tt\",\n",
    "              \"SER_asr_sp\", \"NSER_asr_sp\", \"LER_asr_sp\", \"LWER_asr_sp\", \"DAER_asr_sp\",\n",
    "              \"ASER_trans_tt\", \"ASER_trans_sp\", \"ASER_asr_tt\", \"ASER_asr_sp\",]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = new_df.da_turn_orig.tolist()\n",
    "tokens = [label for ref in tokens for label in ref]\n",
    "temp = new_df.labels.tolist()\n",
    "labels = [label for ref in temp for label in ref]\n",
    "sp = new_df.hyps_trans_sp.tolist()\n",
    "hyps_sp = [label for ref in sp for label in ref]\n",
    "tt = new_df.hyps_trans_tt.tolist()\n",
    "hyps_tt = [label for ref in tt for label in ref]\n",
    "\n",
    "idxlen = [len(x) for x in tokens]\n",
    "idxs = []\n",
    "i = 0\n",
    "for ilen in idxlen:\n",
    "    idxs += [i] * ilen\n",
    "    i += 1\n",
    "\n",
    "tups = list(zip(idxs, tokens, labels, hyps_sp, hyps_tt))\n",
    "missed_segments_sp = [x for x in tups if x[-2]=='I' and x[2]!=x[-2]]\n",
    "missed_segments_tt = [x for x in tups if x[-1]=='I' and x[2]!=x[-1]]\n",
    "\n",
    "inserted_segments_sp = [x for x in tups if x[2]=='I' and x[2]!=x[-2]]\n",
    "inserted_segments_tt = [x for x in tups if x[2]=='I' and x[2]!=x[-1]]\n",
    "\n",
    "total_segments = len([x for x in labels if x != \"I\"])\n",
    "print(\"Total number of segments\", total_segments)\n",
    "print(\"Number of missed segments, speech model:\", len(missed_segments_sp))\n",
    "print(\"Number of missed segments, text model:\", len(missed_segments_tt))\n",
    "print(\"Number of inserted segments, speech model:\", len(inserted_segments_sp))\n",
    "print(\"Number of inserted segments, text model:\", len(inserted_segments_tt))\n",
    "print()\n",
    "print(\"Most common tokens associated with missed E_, speech model\")\n",
    "print(Counter([x[1] for x in missed_segments_sp]).most_common(15))\n",
    "print(\"Most common tokens associated with inserted E_, speech model\")\n",
    "print(Counter([x[1] for x in inserted_segments_sp]).most_common(15))\n",
    "print()\n",
    "print(\"Most common tokens associated with missed E_, text model\")\n",
    "print(Counter([x[1] for x in missed_segments_tt]).most_common(15))\n",
    "print(\"Most common tokens associated with inserted E_, text model\")\n",
    "print(Counter([x[1] for x in inserted_segments_tt]).most_common(15))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missed_segments_sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tups: idxs, tokens, labels, hyps_sp, hyps_tt\n",
    "#sp_sv = [x for x in tups if x[-2]=='E_sv' and x[2]!=x[-2]]\n",
    "#sp_sd = [x for x in tups if x[-2]=='E_sd' and x[2]!=x[-2] and x[-1]!=x[-2]]\n",
    "\n",
    "print(len([x for x in tups if x[-2] == \"E_sv\"]))\n",
    "print(len([x for x in tups if x[-2] == \"E_sd\"]))\n",
    "print(len([x for x in tups if x[-1] == \"E_sv\"]))\n",
    "print(len([x for x in tups if x[-1] == \"E_sd\"]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.28216704288939054"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "500/(500 + 1272)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.22115925717501406"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "393/(393 + 1384)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sptt_diff_DER',\n",
       " 'sptt_diff_DSER',\n",
       " 'sptt_diff_trans_SER',\n",
       " 'sptt_diff_trans_NSER',\n",
       " 'sptt_diff_trans_LER',\n",
       " 'sptt_diff_trans_LWER',\n",
       " 'sptt_diff_trans_DAER',\n",
       " 'sptt_diff_trans_ASER',\n",
       " 'sptt_diff_asr_SER',\n",
       " 'sptt_diff_asr_NSER',\n",
       " 'sptt_diff_asr_LER',\n",
       " 'sptt_diff_asr_LWER',\n",
       " 'sptt_diff_asr_DAER',\n",
       " 'sptt_diff_asr_ASER']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "measure_cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find specific examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col = \"sptt_diff_asr_LWER\"\n",
    "new_df.sort_values(col)[['main_id', 'wer_x','num_seg_label', 'da_turn_orig']][-50:-20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#loc = 387\n",
    "loc = 1634\n",
    "print(\"TIMES\", \"loc =\", loc, new_df.iloc[loc].main_id)\n",
    "print(new_df.iloc[loc].start_times_orig[0], new_df.iloc[loc].end_times_orig[-1])\n",
    "print(new_df.iloc[loc].start_times_asr[0], new_df.iloc[loc].end_times_asr[-1])\n",
    "\n",
    "new_df.iloc[loc][metric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "new_df.iloc[loc][measure_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = list(zip(new_df.iloc[loc].da_turn_orig, new_df.iloc[loc].labels))\n",
    "b1 = list(zip(new_df.iloc[loc].da_turn_orig, new_df.iloc[loc].hyps_trans_sp))\n",
    "b2 = list(zip(new_df.iloc[loc].da_turn_asr, new_df.iloc[loc].hyps_asr_sp))\n",
    "b3 = list(zip(new_df.iloc[loc].da_turn_asr, new_df.iloc[loc].hyps_asr_tt))\n",
    "\n",
    "# PRINT LABEL & TRANSCRIPT SEQUENCE\n",
    "for x,y,x2 in list(zip(new_df.iloc[loc].labels, new_df.iloc[loc].da_turn_orig, new_df.iloc[loc].hyps_trans_tt)):\n",
    "    print(y, \"\\t\\t\", x, \"\\t\", x2)\n",
    "print()\n",
    "\n",
    "for x,y,x2 in list(zip(new_df.iloc[loc].labels, new_df.iloc[loc].da_turn_orig, new_df.iloc[loc].hyps_trans_sp)):\n",
    "    print(y, \"\\t\\t\", x, \"\\t\", x2)\n",
    "print()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# PRINT LABEL & ASR SEQUENCE\n",
    "\n",
    "print_sseq(a, b3, tags=True)\n",
    "print()\n",
    "print_sseq(a, b2, tags=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confusion matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = new_df.da_turn_orig.tolist()\n",
    "tokens = [label for ref in tokens for label in ref]\n",
    "temp = new_df.labels.tolist()\n",
    "labels = [label for ref in temp for label in ref]\n",
    "sp = new_df.hyps_trans_sp.tolist()\n",
    "hyps_sp = [label for ref in sp for label in ref]\n",
    "tt = new_df.hyps_trans_tt.tolist()\n",
    "hyps_tt = [label for ref in tt for label in ref]\n",
    "\n",
    "\n",
    "classes = list(label_map.values())\n",
    "#subclasses = [\"I\", \"E_sd\", \"E_sv\", \"E_%\", \"E_b\", \"E_aa\", \"E_ba\", \"E_bh\", \"E_qy\", \"E_qy^d\"]\n",
    "subclasses = [\"E_sd\", \"E_sv\", \"E_%\", \"E_b\", \"E_aa\", \"E_ba\", \"E_bh\", \"E_qy\", \"E_qy^d\"]\n",
    "\n",
    "subclasses1 = [\"E_sd\", \"E_sv\", \"E_qy\", \"E_qy^d\"]\n",
    "subclasses2 = [\"E_b\", \"E_aa\", \"E_ba\", \"E_bh\"]\n",
    "subclasses3 = [\"E_b\", \"E_ba\"]\n",
    "\n",
    "cm = confusion_matrix(labels, hyps_sp, labels=subclasses)\n",
    "#plot_confusion_matrix(cm, subclasses, title=\"Speech Model\")\n",
    "\n",
    "#print(cm)\n",
    "#sum(cm[0][1:])\n",
    "\n",
    "cm = confusion_matrix(labels, hyps_tt, labels=subclasses)\n",
    "#plot_confusion_matrix(cm, subclasses, title=\"Text Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "labels_short = [x for x in labels if \"E_\" in x]\n",
    "hyps_sp_short = [x for x in hyps_sp if \"E_\" in x] \n",
    "hyps_tt_short =  [x for x in hyps_tt if \"E_\" in x] \n",
    "\n",
    "df = align_sseq(list(zip(labels_short,labels_short)), list(zip(hyps_sp_short,hyps_sp_short)))\n",
    "ref_labels = df.tags_label.tolist()\n",
    "hyp_labels = df.tags_pred.tolist()\n",
    "\n",
    "cm = confusion_matrix(ref_labels, hyp_labels, labels=subclasses)\n",
    "plot_confusion_matrix(cm, subclasses, title=\"Speech Model\")\n",
    "\n",
    "#print(cm)\n",
    "#sum(cm[0][1:])\n",
    "\n",
    "df = align_sseq(list(zip(labels_short,labels_short)), list(zip(hyps_tt_short,hyps_tt_short)))\n",
    "ref_labels = df.tags_label.tolist()\n",
    "hyp_labels = df.tags_pred.tolist()\n",
    "cm = confusion_matrix(ref_labels, hyp_labels, labels=subclasses)\n",
    "plot_confusion_matrix(cm, subclasses, title=\"Text Model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# SLER cms\n",
    "labels_short = [[x for x in y if \"E_\" in x] for y in temp]\n",
    "hyps_sp_short =  [[x for x in y if \"E_\" in x] for y in sp]\n",
    "hyps_tt_short =  [[x for x in y if \"E_\" in x] for y in tt]\n",
    "\n",
    "sp_table = np.zeros((len(subclasses), len(subclasses)))\n",
    "for ref, hyp in zip(labels_short, hyps_sp_short):\n",
    "    df = align_sseq(list(zip(ref,ref)), list(zip(hyp,hyp)))\n",
    "    ref_labels = df.tags_label.tolist()\n",
    "    hyp_labels = df.tags_pred.tolist()\n",
    "    print(ref_labels, hyp_labels)\n",
    "    cm = confusion_matrix(ref_labels, hyp_labels, labels=subclasses)\n",
    "    sp_table = sp_table + cm\n",
    "    \n",
    "sp_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "err_sp = [(x,y) for x,y in list(zip(labels, hyps_sp)) if x!=y]\n",
    "\n",
    "ys_true = [x[0] for x in err_sp]\n",
    "ys_pred = [x[1] for x in err_sp]\n",
    "\n",
    "csl = Counter(ys_true) # most frequently missed labels\n",
    "csh = Counter(ys_pred) # most frequently falsely recognized labels\n",
    "\n",
    "slabel_err = [x[0] for x in csl.most_common(10)]\n",
    "spred_err = [x[0] for x in csh.most_common(10)]\n",
    "sclasses = set(spred_err).union(set(slabel_err))\n",
    "\n",
    "err_tt = [(x,y) for x,y in list(zip(labels, hyps_tt)) if x!=y]\n",
    "yt_true = [x[0] for x in err_tt]\n",
    "yt_pred = [x[1] for x in err_tt]\n",
    "\n",
    "ctl = Counter(yt_true)\n",
    "cth = Counter(yt_pred)\n",
    "\n",
    "tlabel_err = [x[0] for x in ctl.most_common(10)]\n",
    "tpred_err = [x[0] for x in cth.most_common(10)]\n",
    "tclasses = set(tpred_err).union(set(tlabel_err))\n",
    "\n",
    "common_classes = tclasses.intersection(sclasses)\n",
    "common_classes\n",
    "\n",
    "#[x for x in err_sp if x[0] == \"I\" and x[1] == \"E_%\"]\n",
    "# csl.most_common()\n",
    "# csh.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(ys_true, ys_pred, labels=sorted(common_classes))\n",
    "plot_confusion_matrix(cm, sorted(common_classes), title=\"Most Common Errors -- Prosody Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cm = confusion_matrix(yt_true, yt_pred, labels=sorted(common_classes))\n",
    "plot_confusion_matrix(cm, sorted(common_classes), title=\"Most Common Errors -- Text Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tclasses.difference(sclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sclasses.difference(tclasses)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Misc "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row specific (debug)\n",
    "sseq = SequenceMatcher(None, row.da_turn_asr, row.da_turn_orig)\n",
    "\n",
    "ref_side = list(zip(range(len(row.labels)),row.labels, row.start_times_orig, row.end_times_orig, row.da_turn_orig))\n",
    "ref_segments = [x for x in ref_side if \"E\" in x[1]]\n",
    "hyp_side = list(zip(range(len(row.hyps_asr)), row.hyps_asr, row.start_times_asr, row.end_times_asr, row.da_turn_asr))\n",
    "hyp_segments = [x for x in hyp_side if \"E\" in x[1]]\n",
    "\n",
    "\n",
    "ref_list = res_df.labels.tolist()\n",
    "trans_list = res_df.hyps_trans.tolist()\n",
    "asr_list = res_df.hyps_asr.tolist()\n",
    "\n",
    "batch_metrics(ref_list, trans_list)\n",
    "\n",
    "batch_metrics_asr(ref_list, asr_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [\"aa\", \"sv\", \"sv\", \"sv\", \"sv\"]\n",
    "b = [\"aa\", \"sd\", \"sd\", \"sd\", \"ny\", \"ny\"]\n",
    "\n",
    "sseq = SequenceMatcher(None, a, b)\n",
    "sseq.get_opcodes()\n",
    "\n",
    "#print(levenshtein(a, b) / len(a))\n",
    "#print(jiwer.wer(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "loc = 1600\n",
    "a = list(zip(new_df.iloc[loc].da_turn_orig, new_df.iloc[loc].labels))\n",
    "b1 = list(zip(new_df.iloc[loc].da_turn_orig, new_df.iloc[loc].hyps_trans_sp))\n",
    "b2 = list(zip(new_df.iloc[loc].da_turn_asr, new_df.iloc[loc].hyps_asr_sp))\n",
    "b3 = list(zip(new_df.iloc[loc].da_turn_asr, new_df.iloc[loc].hyps_asr_tt))\n",
    "\n",
    "adf = align_sseq(a, b3)\n",
    "print(instance_metrics_asr(new_df.iloc[loc].labels, new_df.iloc[loc].hyps_asr_sp))\n",
    "print(\"aser:\",compute_aser(a, b2))\n",
    "\n",
    "adf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = tt1000_df.copy()\n",
    "df['time_ser'] = df.apply(lambda row: calc_time_ser(row.labels, \n",
    "              row.hyps_asr, \n",
    "              row.start_times_orig, \n",
    "              row.end_times_orig, \n",
    "              row.start_times_asr, \n",
    "              row.end_times_asr), axis=1)\n",
    "\n",
    "print(df['time_ser'].mean())\n",
    "print()\n",
    "\n",
    "l = df.labels.tolist()\n",
    "l = [item for sublist in l for item in sublist]\n",
    "h = df.hyps_asr.tolist()\n",
    "h = [item for sublist in h for item in sublist]\n",
    "sorig = df.start_times_orig.tolist()\n",
    "sorig = [item for sublist in sorig for item in sublist]\n",
    "eorig = df.end_times_orig.tolist()\n",
    "eorig = [item for sublist in eorig for item in sublist]\n",
    "sasr = df.start_times_asr.tolist()\n",
    "sasr = [item for sublist in sasr for item in sublist]\n",
    "easr = df.end_times_asr.tolist()\n",
    "easr = [item for sublist in easr for item in sublist]\n",
    "\n",
    "calc_time_ser(l, h, sorig, eorig, sasr, easr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = sp10004_df.copy()\n",
    "df['time_ser'] = df.apply(lambda row: calc_time_ser(row.labels, \n",
    "              row.hyps_asr, \n",
    "              row.start_times_orig, \n",
    "              row.end_times_orig, \n",
    "              row.start_times_asr, \n",
    "              row.end_times_asr), axis=1)\n",
    "\n",
    "print(df['time_ser'].mean())\n",
    "print()\n",
    "\n",
    "l = df.labels.tolist()\n",
    "l = [item for sublist in l for item in sublist]\n",
    "h = df.hyps_asr.tolist()\n",
    "h = [item for sublist in h for item in sublist]\n",
    "sorig = df.start_times_orig.tolist()\n",
    "sorig = [item for sublist in sorig for item in sublist]\n",
    "eorig = df.end_times_orig.tolist()\n",
    "eorig = [item for sublist in eorig for item in sublist]\n",
    "sasr = df.start_times_asr.tolist()\n",
    "sasr = [item for sublist in sasr for item in sublist]\n",
    "easr = df.end_times_asr.tolist()\n",
    "easr = [item for sublist in easr for item in sublist]\n",
    "\n",
    "calc_time_ser(l, h, sorig, eorig, sasr, easr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new3_df.iloc[loc][metric_cols]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc, new3_df.iloc[loc].main_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "a = list(zip(new3_df.iloc[loc].da_turn_orig, new3_df.iloc[loc].labels))\n",
    "b1 = list(zip(new3_df.iloc[loc].da_turn_orig, new3_df.iloc[loc].hyps_trans_sp))\n",
    "b2 = list(zip(new3_df.iloc[loc].da_turn_asr, new3_df.iloc[loc].hyps_asr_sp))\n",
    "b3 = list(zip(new3_df.iloc[loc].da_turn_asr, new3_df.iloc[loc].hyps_asr_tt))\n",
    "\n",
    "# PRINT LABEL & TRANSCRIPT SEQUENCE\n",
    "for x,y,x2 in list(zip(new3_df.iloc[loc].labels, new3_df.iloc[loc].da_turn_orig, new3_df.iloc[loc].hyps_trans_tt)):\n",
    "    print(y, \"\\t\\t\", x, \"\\t\", x2)\n",
    "print()\n",
    "\n",
    "for x,y,x2 in list(zip(new3_df.iloc[loc].labels, new3_df.iloc[loc].da_turn_orig, new3_df.iloc[loc].hyps_trans_sp)):\n",
    "    print(y, \"\\t\\t\", x, \"\\t\", x2)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print_sseq(a, b3, tags=True)\n",
    "print()\n",
    "print_sseq(a, b2, tags=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "temp_df = pd.merge(new_df, new3_df, on='main_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(temp_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "temp_df[temp_df.DSER_sp_x < temp_df.DSER_sp_y][[\"DSER_sp_x\", \"DSER_sp_y\", \"DER_sp_x\", \"DER_sp_y\", \"num_seg_label_x\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(zip(new_df.iloc[1425].start_times_orig, new_df.iloc[1382].end_times_orig)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6-torch1.7-cpu",
   "language": "python",
   "name": "py3.6-torch1.7-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
