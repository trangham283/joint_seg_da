{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load metric_helpers\n",
    "import json\n",
    "import os\n",
    "import sys\n",
    "import re\n",
    "import glob\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import jiwer\n",
    "\n",
    "from difflib import SequenceMatcher\n",
    "from sklearn.metrics import f1_score\n",
    "from collections import Counter\n",
    "\n",
    "def levenshtein(s1, s2):\n",
    "    if len(s1) < len(s2):\n",
    "        return levenshtein(s2, s1)\n",
    "    # len(s1) >= len(s2)\n",
    "    if len(s2) == 0:\n",
    "        return len(s1)\n",
    "    previous_row = range(len(s2) + 1)\n",
    "    for (i, c1) in enumerate(s1):\n",
    "        current_row = [i + 1]\n",
    "        for (j, c2) in enumerate(s2):\n",
    "            insertions = previous_row[j + 1] + 1  # j+1 instead of j since\n",
    "            deletions = current_row[j] + 1  # than s2\n",
    "            substitutions = previous_row[j] + (c1 != c2)\n",
    "            current_row.append(min(insertions, deletions, substitutions))\n",
    "        previous_row = current_row\n",
    "    return previous_row[-1]\n",
    "\n",
    "\n",
    "def instance_metrics(ref_labels, hyp_labels):\n",
    "    segment_records = []\n",
    "    n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors = 0, 0, 0\n",
    "    for ref, hyp in zip(ref_labels, hyp_labels):\n",
    "        n_segment_tokens += 1\n",
    "        if hyp[0] != ref[0]:\n",
    "            n_segment_seg_errors += 1\n",
    "        if hyp != ref:\n",
    "            n_segment_joint_errors += 1\n",
    "        if ref.startswith(\"E\"):\n",
    "            segment_records.append((n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors))\n",
    "            n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors = 0, 0, 0\n",
    "    \n",
    "    n_segments = len(segment_records)\n",
    "    n_tokens = 0\n",
    "    n_wrong_seg_segments = 0\n",
    "    n_wrong_seg_tokens = 0\n",
    "    n_wrong_joint_segments = 0\n",
    "    n_wrong_joint_tokens = 0\n",
    "    for (n_segment_tokens, n_segment_seg_errors, n_segment_joint_errors) in segment_records:\n",
    "        n_tokens += n_segment_tokens\n",
    "        if n_segment_seg_errors > 0:\n",
    "            n_wrong_seg_segments += 1\n",
    "            n_wrong_seg_tokens += n_segment_tokens\n",
    "        if n_segment_joint_errors > 0:\n",
    "            n_wrong_joint_segments += 1\n",
    "            n_wrong_joint_tokens += n_segment_tokens\n",
    "\n",
    "    DSER = n_wrong_seg_segments / n_segments\n",
    "    strict_seg_err = n_wrong_seg_tokens / n_tokens\n",
    "    DER = n_wrong_joint_segments / n_segments\n",
    "    strict_joint_err = n_wrong_joint_tokens / n_tokens\n",
    "\n",
    "    ref_short = [x for x in ref_labels if x != \"I\"]\n",
    "    hyp_short = [x for x in hyp_labels if x != \"I\"]\n",
    "    lwer = jiwer.wer(ref_short, hyp_short)\n",
    "    return {\n",
    "        \"DSER\": DSER,\n",
    "        \"strict segmentation error\": strict_seg_err,\n",
    "        \"DER\": DER,\n",
    "        \"strict joint error\": strict_joint_err,\n",
    "        \"LWER\": lwer\n",
    "    }\n",
    "\n",
    "def batch_metrics(refs, hyps):\n",
    "    score_lists = {\n",
    "        \"DSER\": [],\n",
    "        \"strict segmentation error\": [],\n",
    "        \"DER\": [],\n",
    "        \"strict joint error\": [],\n",
    "        \"LWER\": []\n",
    "    }\n",
    "    for ref_labels, hyp_labels in zip(refs, hyps):\n",
    "        this_metrics = instance_metrics(ref_labels, hyp_labels)\n",
    "        for k, v in this_metrics.items():\n",
    "            score_lists[k].append(v)\n",
    "\n",
    "    flattened_refs = [label for ref in refs for label in ref]\n",
    "    flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "    macro_f1 = f1_score(flattened_refs, flattened_hyps, average=\"macro\")\n",
    "    micro_f1 = f1_score(flattened_refs, flattened_hyps, average=\"micro\")\n",
    "    flat_ref_short = [x for x in flattened_refs if x != \"I\"]\n",
    "    flat_hyp_short = [x for x in flattened_hyps if x != \"I\"]\n",
    "    lwer = jiwer.wer(flat_ref_short, flat_hyp_short)\n",
    "\n",
    "    return {\n",
    "        \"DSER\": np.mean(score_lists[\"DSER\"]),\n",
    "        \"strict segmentation error\": np.mean(score_lists[\"strict segmentation error\"]),\n",
    "        \"DER\": np.mean(score_lists[\"DER\"]),\n",
    "        \"strict joint error\": np.mean(score_lists[\"strict joint error\"]),\n",
    "        \"Macro F1\": macro_f1,\n",
    "        \"Micro F1\": micro_f1,\n",
    "        \"Macro LWER\": np.mean(score_lists[\"LWER\"]),\n",
    "        \"Micro LWER\": lwer,\n",
    "    }\n",
    "\n",
    "def instance_metrics_asr(ref_labels, hyp_labels, dist_fn=levenshtein):\n",
    "    ref_short = [x for x in ref_labels if x != \"I\"]\n",
    "    hyp_short = [x for x in hyp_labels if x != \"I\"]\n",
    "    lwer = jiwer.wer(ref_short, hyp_short)\n",
    "\n",
    "    ler = jiwer.wer(ref_labels, hyp_labels)\n",
    "    \n",
    "    t_ids = [i for i, t in enumerate(ref_labels) if \"E\" in t]\n",
    "    r_ids = [i for i, r in enumerate(hyp_labels) if \"E\" in r]\n",
    "    s = 0\n",
    "    for t in t_ids: s += min([abs(r - t) for r in r_ids])\n",
    "    for r in r_ids: s += min([abs(r - t) for t in t_ids])\n",
    "        \n",
    "    ser = s / 2 / len(ref_short)\n",
    "    nser = abs(len(ref_short) - len(hyp_short)) / len(ref_short)\n",
    "    \n",
    "    new_ref = []\n",
    "    new_hyp = []\n",
    "    offset = 0\n",
    "    for i in t_ids:\n",
    "        new_ref += [ref_labels[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    offset = 0\n",
    "    for i in r_ids:\n",
    "        new_hyp += [hyp_labels[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    daer = jiwer.wer(new_ref, new_hyp)\n",
    "    return {\"LWER\": lwer,\n",
    "            \"LER\": ler,\n",
    "            \"SER\": ser,\n",
    "            \"NSER\": nser,\n",
    "            \"DAER\": daer}\n",
    "\n",
    "def batch_metrics_asr(refs, hyps, dist_fn=levenshtein):\n",
    "    score_lists = {\n",
    "        \"LWER\": [],\n",
    "        \"LER\": [],\n",
    "        \"SER\": [],\n",
    "        \"NSER\": [],\n",
    "        \"DAER\": []\n",
    "    }\n",
    "    for ref_labels, hyp_labels in zip(refs, hyps):\n",
    "        this_metrics = instance_metrics_asr(ref_labels, hyp_labels)\n",
    "        for k, v in this_metrics.items():\n",
    "            score_lists[k].append(v)\n",
    "\n",
    "    flattened_refs = [label for ref in refs for label in ref]\n",
    "    flattened_hyps = [label for hyp in hyps for label in hyp]\n",
    "    flat_ref_short = [x for x in flattened_refs if x != \"I\"]\n",
    "    flat_hyp_short = [x for x in flattened_hyps if x != \"I\"]\n",
    "    lwer = jiwer.wer(flat_ref_short, flat_hyp_short)\n",
    "    ler = jiwer.wer(flattened_refs, flattened_hyps)\n",
    "    \n",
    "    t_ids = [i for i, t in enumerate(flattened_refs) if \"E\" in t]\n",
    "    r_ids = [i for i, r in enumerate(flattened_hyps) if \"E\" in r]\n",
    "    s = 0\n",
    "    for t in t_ids: s += min([abs(r - t) for r in r_ids])\n",
    "    for r in r_ids: s += min([abs(r - t) for t in t_ids])\n",
    "    ser = s / 2 / len(t_ids)\n",
    "    \n",
    "    nser = abs(len(t_ids) - len(r_ids)) / len(t_ids)\n",
    "    \n",
    "    new_ref = []\n",
    "    new_hyp = []\n",
    "    offset = 0\n",
    "    for i in t_ids:\n",
    "        new_ref += [flattened_refs[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    offset = 0\n",
    "    for i in r_ids:\n",
    "        new_hyp += [flattened_hyps[i]] * (i - offset + 1)\n",
    "        offset = i+1 \n",
    "    daer = jiwer.wer(new_ref, new_hyp)\n",
    "\n",
    "    return {\n",
    "        \"Macro LWER\": np.mean(score_lists[\"LWER\"]),\n",
    "        \"Micro LWER\": lwer,\n",
    "        \"Macro LER\": np.mean(score_lists[\"LER\"]),\n",
    "        \"Micro LER\": ler,\n",
    "        \"Macro SER\": np.mean(score_lists[\"SER\"]),\n",
    "        \"Micro SER\": ser,\n",
    "        \"Macro NSER\": np.mean(score_lists[\"NSER\"]),\n",
    "        \"Micro NSER\": nser,\n",
    "        \"Macro DAER\": np.mean(score_lists[\"DAER\"]),\n",
    "        \"Micro DAER\": daer,\n",
    "    }\n",
    "\n",
    "def convert_to_list(this_str, turn_float=False):\n",
    "    this_str = this_str.replace('[', '').replace(']','')\n",
    "    this_str = this_str.replace(\"'\", \"\").replace(\",\",\"\").split()\n",
    "    if turn_float:\n",
    "        this_str = [float(x) for x in this_str]\n",
    "    return this_str\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "ref_dir = \"/homes/ttmt001/transitory/dialog-act-prediction/data/joint/ref_out\"\n",
    "asr_dir = \"/homes/ttmt001/transitory/dialog-act-prediction/data/joint/asr_out\"\n",
    "\n",
    "split_name = 'dev'\n",
    "filename = split + \"_merged.tsv\"\n",
    "merged_df = pd.read_csv(filename, sep=\"\\t\")\n",
    "for column in ['joint_labels', 'da_turn_orig', 'da_turn_asr']:\n",
    "    merged_df[column] = merged_df[column].apply(convert_to_list)\n",
    "for column in ['start_times_orig', 'end_times_orig', 'start_times_asr', 'end_times_asr']:\n",
    "    merged_df[column] = merged_df[column].apply(convert_to_list, turn_float=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_results_df(model_name, split_name, merged_df):\n",
    "    suffix = split_name.upper() + '_' +  model_name + '.res'\n",
    "\n",
    "    trans_file = os.path.join(ref_dir, suffix)\n",
    "    asr_file = os.path.join(asr_dir, suffix)\n",
    "\n",
    "    trans_df = pd.read_csv(trans_file, sep=\"\\t\")\n",
    "    asr_df = pd.read_csv(asr_file, sep=\"\\t\")\n",
    "    asr_df.rename(columns={'PREDS': 'PREDS_ASR'}, inplace=True)\n",
    "    asr_df['PREDS_ASR'] = asr_df.PREDS_ASR.apply(lambda x: x.replace(\" </t>\", \"\"))\n",
    "    preds_df = trans_df.join(asr_df)\n",
    "    preds_df['labels'] = preds_df.LABELS.apply(lambda x: x.split())\n",
    "    preds_df['hyps_trans'] = preds_df.PREDS.apply(lambda x: x.split())\n",
    "    preds_df['hyps_asr'] = preds_df.PREDS_ASR.apply(lambda x: x.split())\n",
    "    preds_df.rename(columns={'TURN_ID': 'main_id'}, inplace=True)\n",
    "    preds_df.drop(columns=['LABELS', 'PREDS', 'PREDS_ASR'], inplace=True)\n",
    "    res_df = pd.merge(preds_df, merged_df, on='main_id')\n",
    "\n",
    "    results = res_df.apply(lambda row: instance_metrics(row.labels, row.hyps_trans), axis=1)\n",
    "    results_asr = res_df.apply(lambda row: instance_metrics_asr(row.labels, row.hyps_asr), axis=1)\n",
    "    results2 = res_df.apply(lambda row: instance_metrics_asr(row.labels, row.hyps_trans), axis=1)\n",
    "\n",
    "    res_df['DSER'] = [x['DSER'] for x in results.tolist()]\n",
    "    res_df['DER'] = [x['DER'] for x in results.tolist()]\n",
    "    res_df['LWER_trans'] = [x['LWER'] for x in results.tolist()]\n",
    "    res_df['LER_trans'] = [x['LER'] for x in results2.tolist()]\n",
    "    res_df['SER_trans'] = [x['SER'] for x in results2.tolist()]\n",
    "    res_df['NSER_trans'] = [x['NSER'] for x in results2.tolist()]\n",
    "    res_df['DAER_trans'] = [x['DAER'] for x in results2.tolist()]\n",
    "\n",
    "    res_df['LWER_asr'] = [x['LWER'] for x in results_asr.tolist()]\n",
    "    res_df['LER_asr'] = [x['LER'] for x in results_asr.tolist()]\n",
    "    res_df['SER_asr'] = [x['SER'] for x in results_asr.tolist()]\n",
    "    res_df['NSER_asr'] = [x['NSER'] for x in results_asr.tolist()]\n",
    "    res_df['DAER_asr'] = [x['DAER'] for x in results_asr.tolist()]\n",
    "\n",
    "    return res_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sp10004_df = get_results_df(\"sp10004\", split_name, merged_df)\n",
    "tt1000_df = get_results_df(\"tt1000\", split_name, merged_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DSER': 0.09619378655376215,\n",
       " 'strict segmentation error': 0.08684014825474667,\n",
       " 'DER': 0.2746146013839729,\n",
       " 'strict joint error': 0.2638527217940235,\n",
       " 'Macro F1': 0.44831366975399234,\n",
       " 'Micro F1': 0.9594272076372314,\n",
       " 'Macro LWER': 0.26291343223924063,\n",
       " 'Micro LWER': 0.28832116788321166}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_metrics(sp10004_df.labels.tolist(), sp10004_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'DSER': 0.09823221825967403,\n",
       " 'strict segmentation error': 0.09068847729502526,\n",
       " 'DER': 0.2873828513700387,\n",
       " 'strict joint error': 0.27953951620043216,\n",
       " 'Macro F1': 0.42853709134282647,\n",
       " 'Micro F1': 0.9575319387898358,\n",
       " 'Macro LWER': 0.27096132800830786,\n",
       " 'Micro LWER': 0.29105839416058393}"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_metrics(tt1000_df.labels.tolist(), tt1000_df.hyps_trans.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Macro LWER': 0.33321915187381934,\n",
       " 'Micro LWER': 0.33728710462287104,\n",
       " 'Macro LER': 0.21200899990605945,\n",
       " 'Micro LER': 0.10420468903551874,\n",
       " 'Macro SER': 1.2919854025711257,\n",
       " 'Micro SER': 10.773874695863746,\n",
       " 'Macro NSER': 0.11498445964583852,\n",
       " 'Micro NSER': 0.11344282238442822,\n",
       " 'Macro DAER': 0.3469696528989709,\n",
       " 'Micro DAER': 0.2585287098132809}"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_metrics_asr(sp10004_df.labels.tolist(), sp10004_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Macro LWER': 0.4048026764774782,\n",
       " 'Micro LWER': 0.37195863746958635,\n",
       " 'Macro LER': 0.2512693816481347,\n",
       " 'Micro LER': 0.10866208058402359,\n",
       " 'Macro SER': 1.2789210061174672,\n",
       " 'Micro SER': 10.78132603406326,\n",
       " 'Macro NSER': 0.10952720251072905,\n",
       " 'Micro NSER': 0.10462287104622871,\n",
       " 'Macro DAER': 0.4183378454485582,\n",
       " 'Micro DAER': 0.26881229818896535}"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch_metrics_asr(tt1000_df.labels.tolist(), tt1000_df.hyps_asr.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>hyps_trans</th>\n",
       "      <th>hyps_asr</th>\n",
       "      <th>joint_labels</th>\n",
       "      <th>da_turn_orig</th>\n",
       "      <th>start_times_orig</th>\n",
       "      <th>end_times_orig</th>\n",
       "      <th>da_turn_asr</th>\n",
       "      <th>start_times_asr</th>\n",
       "      <th>...</th>\n",
       "      <th>LWER_trans</th>\n",
       "      <th>LER_trans</th>\n",
       "      <th>SER_trans</th>\n",
       "      <th>NSER_trans</th>\n",
       "      <th>DAER_trans</th>\n",
       "      <th>LWER_asr</th>\n",
       "      <th>LER_asr</th>\n",
       "      <th>SER_asr</th>\n",
       "      <th>NSER_asr</th>\n",
       "      <th>DAER_asr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2347_B_0001</td>\n",
       "      <td>[I, I, E_fo_o_fw_\"_by_bc]</td>\n",
       "      <td>[I, I, E_fo_o_fw_\"_by_bc]</td>\n",
       "      <td>[E_fo_o_fw_\"_by_bc]</td>\n",
       "      <td>[I, I, E_fo_o_fw_\"_by_bc]</td>\n",
       "      <td>[um, all, right]</td>\n",
       "      <td>[0.005875, 1.087875, 1.25325]</td>\n",
       "      <td>[0.21975, 1.25325, 1.484375]</td>\n",
       "      <td>[alright]</td>\n",
       "      <td>[1.11]</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2347_A_0002</td>\n",
       "      <td>[I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...</td>\n",
       "      <td>[I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "      <td>[I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "      <td>[I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...</td>\n",
       "      <td>[i, \"\", ve, uh, as, far, as, i, \"\", m, concern...</td>\n",
       "      <td>[1.060625, 1.060625, 1.060625, 1.632625, 1.833...</td>\n",
       "      <td>[1.476, 1.476, 1.476, 1.833625, 2.083625, 2.36...</td>\n",
       "      <td>[i, \"\", ve, uh, as, far, as, i, \"\", m, concern...</td>\n",
       "      <td>[1.090625, 1.090625, 1.090625, 1.660625, 1.930...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2347_B_0003</td>\n",
       "      <td>[I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...</td>\n",
       "      <td>[I, E_b, I, I, I, I, I, I, I, I, I, I, I, I, I...</td>\n",
       "      <td>[I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "      <td>[I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...</td>\n",
       "      <td>[uh, huh, oh, well, i, tend, i, tend, to, agre...</td>\n",
       "      <td>[16.56525, 16.56525, 17.74175, 17.915125, 18.0...</td>\n",
       "      <td>[17.0535, 17.0535, 17.915125, 18.085125, 18.15...</td>\n",
       "      <td>[m, ##hm, i, tend, i, tend, to, agree, ah, in,...</td>\n",
       "      <td>[16.56525, 16.56525, 18.09525, 18.18525, 18.54...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.619048</td>\n",
       "      <td>0.052817</td>\n",
       "      <td>3.047619</td>\n",
       "      <td>0.476190</td>\n",
       "      <td>0.383803</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.066901</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.355634</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       main_id                                             labels  \\\n",
       "0  2347_B_0001                          [I, I, E_fo_o_fw_\"_by_bc]   \n",
       "1  2347_A_0002  [I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...   \n",
       "2  2347_B_0003  [I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...   \n",
       "\n",
       "                                          hyps_trans  \\\n",
       "0                          [I, I, E_fo_o_fw_\"_by_bc]   \n",
       "1  [I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
       "2  [I, E_b, I, I, I, I, I, I, I, I, I, I, I, I, I...   \n",
       "\n",
       "                                            hyps_asr  \\\n",
       "0                                [E_fo_o_fw_\"_by_bc]   \n",
       "1  [I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
       "2  [I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
       "\n",
       "                                        joint_labels  \\\n",
       "0                          [I, I, E_fo_o_fw_\"_by_bc]   \n",
       "1  [I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...   \n",
       "2  [I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...   \n",
       "\n",
       "                                        da_turn_orig  \\\n",
       "0                                   [um, all, right]   \n",
       "1  [i, \"\", ve, uh, as, far, as, i, \"\", m, concern...   \n",
       "2  [uh, huh, oh, well, i, tend, i, tend, to, agre...   \n",
       "\n",
       "                                    start_times_orig  \\\n",
       "0                      [0.005875, 1.087875, 1.25325]   \n",
       "1  [1.060625, 1.060625, 1.060625, 1.632625, 1.833...   \n",
       "2  [16.56525, 16.56525, 17.74175, 17.915125, 18.0...   \n",
       "\n",
       "                                      end_times_orig  \\\n",
       "0                       [0.21975, 1.25325, 1.484375]   \n",
       "1  [1.476, 1.476, 1.476, 1.833625, 2.083625, 2.36...   \n",
       "2  [17.0535, 17.0535, 17.915125, 18.085125, 18.15...   \n",
       "\n",
       "                                         da_turn_asr  \\\n",
       "0                                          [alright]   \n",
       "1  [i, \"\", ve, uh, as, far, as, i, \"\", m, concern...   \n",
       "2  [m, ##hm, i, tend, i, tend, to, agree, ah, in,...   \n",
       "\n",
       "                                     start_times_asr  ... LWER_trans  \\\n",
       "0                                             [1.11]  ...   0.000000   \n",
       "1  [1.090625, 1.090625, 1.090625, 1.660625, 1.930...  ...   0.333333   \n",
       "2  [16.56525, 16.56525, 18.09525, 18.18525, 18.54...  ...   0.619048   \n",
       "\n",
       "   LER_trans  SER_trans  NSER_trans  DAER_trans  LWER_asr   LER_asr   SER_asr  \\\n",
       "0   0.000000   0.000000    0.000000    0.000000  0.000000  0.666667  2.000000   \n",
       "1   0.021277   4.333333    0.333333    0.085106  0.333333  0.021277  4.333333   \n",
       "2   0.052817   3.047619    0.476190    0.383803  0.571429  0.066901  4.785714   \n",
       "\n",
       "   NSER_asr  DAER_asr  \n",
       "0  0.000000  0.666667  \n",
       "1  0.333333  0.085106  \n",
       "2  0.428571  0.355634  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp10004_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>main_id</th>\n",
       "      <th>labels</th>\n",
       "      <th>hyps_trans</th>\n",
       "      <th>hyps_asr</th>\n",
       "      <th>joint_labels</th>\n",
       "      <th>da_turn_orig</th>\n",
       "      <th>start_times_orig</th>\n",
       "      <th>end_times_orig</th>\n",
       "      <th>da_turn_asr</th>\n",
       "      <th>start_times_asr</th>\n",
       "      <th>...</th>\n",
       "      <th>LWER_trans</th>\n",
       "      <th>LER_trans</th>\n",
       "      <th>SER_trans</th>\n",
       "      <th>NSER_trans</th>\n",
       "      <th>DAER_trans</th>\n",
       "      <th>LWER_asr</th>\n",
       "      <th>LER_asr</th>\n",
       "      <th>SER_asr</th>\n",
       "      <th>NSER_asr</th>\n",
       "      <th>DAER_asr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2347_B_0001</td>\n",
       "      <td>[I, I, E_fo_o_fw_\"_by_bc]</td>\n",
       "      <td>[I, I, E_b]</td>\n",
       "      <td>[E_b]</td>\n",
       "      <td>[I, I, E_fo_o_fw_\"_by_bc]</td>\n",
       "      <td>[um, all, right]</td>\n",
       "      <td>[0.005875, 1.087875, 1.25325]</td>\n",
       "      <td>[0.21975, 1.25325, 1.484375]</td>\n",
       "      <td>[alright]</td>\n",
       "      <td>[1.11]</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2347_A_0002</td>\n",
       "      <td>[I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...</td>\n",
       "      <td>[I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "      <td>[I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...</td>\n",
       "      <td>[I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...</td>\n",
       "      <td>[i, \"\", ve, uh, as, far, as, i, \"\", m, concern...</td>\n",
       "      <td>[1.060625, 1.060625, 1.060625, 1.632625, 1.833...</td>\n",
       "      <td>[1.476, 1.476, 1.476, 1.833625, 2.083625, 2.36...</td>\n",
       "      <td>[i, \"\", ve, uh, as, far, as, i, \"\", m, concern...</td>\n",
       "      <td>[1.090625, 1.090625, 1.090625, 1.660625, 1.930...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.085106</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.021277</td>\n",
       "      <td>4.333333</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.085106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2347_B_0003</td>\n",
       "      <td>[I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...</td>\n",
       "      <td>[I, E_b, I, I, I, I, I, I, I, E_sd, I, I, I, I...</td>\n",
       "      <td>[I, E_aa, I, I, I, I, I, E_aa, I, I, I, I, I, ...</td>\n",
       "      <td>[I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...</td>\n",
       "      <td>[uh, huh, oh, well, i, tend, i, tend, to, agre...</td>\n",
       "      <td>[16.56525, 16.56525, 17.74175, 17.915125, 18.0...</td>\n",
       "      <td>[17.0535, 17.0535, 17.915125, 18.085125, 18.15...</td>\n",
       "      <td>[m, ##hm, i, tend, i, tend, to, agree, ah, in,...</td>\n",
       "      <td>[16.56525, 16.56525, 18.09525, 18.18525, 18.54...</td>\n",
       "      <td>...</td>\n",
       "      <td>0.428571</td>\n",
       "      <td>0.056338</td>\n",
       "      <td>1.761905</td>\n",
       "      <td>0.142857</td>\n",
       "      <td>0.260563</td>\n",
       "      <td>0.238095</td>\n",
       "      <td>0.070423</td>\n",
       "      <td>2.666667</td>\n",
       "      <td>0.047619</td>\n",
       "      <td>0.197183</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       main_id                                             labels  \\\n",
       "0  2347_B_0001                          [I, I, E_fo_o_fw_\"_by_bc]   \n",
       "1  2347_A_0002  [I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...   \n",
       "2  2347_B_0003  [I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...   \n",
       "\n",
       "                                          hyps_trans  \\\n",
       "0                                        [I, I, E_b]   \n",
       "1  [I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
       "2  [I, E_b, I, I, I, I, I, I, I, E_sd, I, I, I, I...   \n",
       "\n",
       "                                            hyps_asr  \\\n",
       "0                                              [E_b]   \n",
       "1  [I, I, I, I, I, I, I, I, I, I, I, I, I, I, I, ...   \n",
       "2  [I, E_aa, I, I, I, I, I, E_aa, I, I, I, I, I, ...   \n",
       "\n",
       "                                        joint_labels  \\\n",
       "0                          [I, I, E_fo_o_fw_\"_by_bc]   \n",
       "1  [I, I, I, E_%, I, I, I, I, I, I, I, I, I, I, I...   \n",
       "2  [I, E_aa, I, I, I, I, I, I, I, E_aa, I, I, I, ...   \n",
       "\n",
       "                                        da_turn_orig  \\\n",
       "0                                   [um, all, right]   \n",
       "1  [i, \"\", ve, uh, as, far, as, i, \"\", m, concern...   \n",
       "2  [uh, huh, oh, well, i, tend, i, tend, to, agre...   \n",
       "\n",
       "                                    start_times_orig  \\\n",
       "0                      [0.005875, 1.087875, 1.25325]   \n",
       "1  [1.060625, 1.060625, 1.060625, 1.632625, 1.833...   \n",
       "2  [16.56525, 16.56525, 17.74175, 17.915125, 18.0...   \n",
       "\n",
       "                                      end_times_orig  \\\n",
       "0                       [0.21975, 1.25325, 1.484375]   \n",
       "1  [1.476, 1.476, 1.476, 1.833625, 2.083625, 2.36...   \n",
       "2  [17.0535, 17.0535, 17.915125, 18.085125, 18.15...   \n",
       "\n",
       "                                         da_turn_asr  \\\n",
       "0                                          [alright]   \n",
       "1  [i, \"\", ve, uh, as, far, as, i, \"\", m, concern...   \n",
       "2  [m, ##hm, i, tend, i, tend, to, agree, ah, in,...   \n",
       "\n",
       "                                     start_times_asr  ... LWER_trans  \\\n",
       "0                                             [1.11]  ...   1.000000   \n",
       "1  [1.090625, 1.090625, 1.090625, 1.660625, 1.930...  ...   0.333333   \n",
       "2  [16.56525, 16.56525, 18.09525, 18.18525, 18.54...  ...   0.428571   \n",
       "\n",
       "   LER_trans  SER_trans  NSER_trans  DAER_trans  LWER_asr   LER_asr   SER_asr  \\\n",
       "0   0.333333   0.000000    0.000000    1.000000  1.000000  1.000000  2.000000   \n",
       "1   0.021277   4.333333    0.333333    0.085106  0.333333  0.021277  4.333333   \n",
       "2   0.056338   1.761905    0.142857    0.260563  0.238095  0.070423  2.666667   \n",
       "\n",
       "   NSER_asr  DAER_asr  \n",
       "0  0.000000  1.000000  \n",
       "1  0.333333  0.085106  \n",
       "2  0.047619  0.197183  \n",
       "\n",
       "[3 rows x 24 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1000_df.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Row specific (debug)\n",
    "sseq = SequenceMatcher(None, row.da_turn_asr, row.da_turn_orig)\n",
    "\n",
    "ref_side = list(zip(range(len(row.labels)),row.labels, row.start_times_orig, row.end_times_orig, row.da_turn_orig))\n",
    "ref_segments = [x for x in ref_side if \"E\" in x[1]]\n",
    "hyp_side = list(zip(range(len(row.hyps_asr)), row.hyps_asr, row.start_times_asr, row.end_times_asr, row.da_turn_asr))\n",
    "hyp_segments = [x for x in hyp_side if \"E\" in x[1]]\n",
    "\n",
    "\n",
    "ref_list = res_df.labels.tolist()\n",
    "trans_list = res_df.hyps_trans.tolist()\n",
    "asr_list = res_df.hyps_asr.tolist()\n",
    "\n",
    "batch_metrics(ref_list, trans_list)\n",
    "\n",
    "batch_metrics_asr(ref_list, asr_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8\n",
      "0.8\n"
     ]
    }
   ],
   "source": [
    "a = [\"aa\", \"sv\", \"sv\", \"sv\", \"sv\"]\n",
    "b = [\"aa\", \"sd\", \"sd\", \"sd\"]\n",
    "\n",
    "print(levenshtein(a, b) / len(a))\n",
    "print(jiwer.wer(a, b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "tt1000_df['check'] = tt1000_df.apply(lambda row: jiwer.wer(row.labels, row.hyps_trans), axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>check</th>\n",
       "      <th>LER_trans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.021277</td>\n",
       "      <td>0.021277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.056338</td>\n",
       "      <td>0.056338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.095238</td>\n",
       "      <td>0.095238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1634</th>\n",
       "      <td>0.148148</td>\n",
       "      <td>0.148148</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1635</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1636</th>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.067797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1637</th>\n",
       "      <td>0.038168</td>\n",
       "      <td>0.038168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1638</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1639 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         check  LER_trans\n",
       "0     0.333333   0.333333\n",
       "1     0.021277   0.021277\n",
       "2     0.056338   0.056338\n",
       "3     0.095238   0.095238\n",
       "4     0.000000   0.000000\n",
       "...        ...        ...\n",
       "1634  0.148148   0.148148\n",
       "1635  0.000000   0.000000\n",
       "1636  0.067797   0.067797\n",
       "1637  0.038168   0.038168\n",
       "1638  0.000000   0.000000\n",
       "\n",
       "[1639 rows x 2 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tt1000_df[['check', 'LER_trans']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py3.6-torch1.7-cpu",
   "language": "python",
   "name": "py3.6-torch1.7-cpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
